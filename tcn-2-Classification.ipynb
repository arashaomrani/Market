{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, scale\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.layers import Add, LSTM, Activation, Flatten, Dropout, Lambda, Conv1D, Input, BatchNormalization\n",
    "from keras.models import Model\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "py.init_notebook_mode(connected=True)\n",
    "from googlefinance.client import get_price_data, get_prices_data, get_prices_time_data\n",
    "import fix_yahoo_finance as yf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4297</th>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>194.990005</td>\n",
       "      <td>195.190002</td>\n",
       "      <td>190.100006</td>\n",
       "      <td>190.979996</td>\n",
       "      <td>190.979996</td>\n",
       "      <td>24024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4298</th>\n",
       "      <td>2018-07-30</td>\n",
       "      <td>191.899994</td>\n",
       "      <td>192.199997</td>\n",
       "      <td>189.070007</td>\n",
       "      <td>189.910004</td>\n",
       "      <td>189.910004</td>\n",
       "      <td>21029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4299</th>\n",
       "      <td>2018-07-31</td>\n",
       "      <td>190.300003</td>\n",
       "      <td>192.139999</td>\n",
       "      <td>189.339996</td>\n",
       "      <td>190.289993</td>\n",
       "      <td>190.289993</td>\n",
       "      <td>39373000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>199.130005</td>\n",
       "      <td>201.759995</td>\n",
       "      <td>197.309998</td>\n",
       "      <td>201.500000</td>\n",
       "      <td>201.500000</td>\n",
       "      <td>67841600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4301</th>\n",
       "      <td>2018-08-02</td>\n",
       "      <td>200.580002</td>\n",
       "      <td>208.380005</td>\n",
       "      <td>200.350006</td>\n",
       "      <td>207.800003</td>\n",
       "      <td>207.800003</td>\n",
       "      <td>50325158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close   Adj Close  \\\n",
       "4297  2018-07-27  194.990005  195.190002  190.100006  190.979996  190.979996   \n",
       "4298  2018-07-30  191.899994  192.199997  189.070007  189.910004  189.910004   \n",
       "4299  2018-07-31  190.300003  192.139999  189.339996  190.289993  190.289993   \n",
       "4300  2018-08-01  199.130005  201.759995  197.309998  201.500000  201.500000   \n",
       "4301  2018-08-02  200.580002  208.380005  200.350006  207.800003  207.800003   \n",
       "\n",
       "        Volume  \n",
       "4297  24024000  \n",
       "4298  21029500  \n",
       "4299  39373000  \n",
       "4300  67841600  \n",
       "4301  50325158  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stock=\"AAPL\"\n",
    "param = {\n",
    "    'q': Stock, # Stock symbol (ex: \"AAPL\")\n",
    "    'i': \"86400\", # Interval size in seconds (\"86400\" = 1 day intervals)\n",
    "    # Stock exchange symbol on which stock is traded (ex: \"NASD\")\n",
    "     'p':'5Y'# Period (Ex: \"1Y\" = 1 year)\n",
    "}\n",
    "# get price data (return pandas dataframe)\n",
    "#df = get_price_data(param)\n",
    "  \n",
    "#df = yf.download(Stock,'2001-10-06')\n",
    "#df.to_csv(Stock+'.csv')\n",
    "df=pd.read_csv(Stock+'.csv')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df\n",
    "data['Close'].replace(0, np.nan, inplace=True)\n",
    "data['Close'].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bolinger_Bands(stock_price, window_size, num_of_std):\n",
    "\n",
    "    rolling_mean = stock_price.rolling(window=window_size).mean()\n",
    "    rolling_std  = stock_price.rolling(window=window_size).std()\n",
    "    upper_band = rolling_mean + (rolling_std*num_of_std)\n",
    "    lower_band = rolling_mean - (rolling_std*num_of_std)\n",
    "\n",
    "    return rolling_mean, upper_band, lower_band\n",
    "Avg, Upper, Lower = Bolinger_Bands(data['Close'], 10, 2)\n",
    "def OBV(data):\n",
    "    last_obv = 0\n",
    "    obv = [last_obv]\n",
    "    for i in range(1,len(data)):\n",
    "        if data['Close'][i] >= data['Close'][i-1]:\n",
    "            obv.append(last_obv + data['Volume'][i])\n",
    "        else:\n",
    "            obv.append(last_obv - data['Volume'][i])\n",
    "        last_obv = obv[-1]\n",
    "    return pd.DataFrame(obv, columns=['OBV'])\n",
    "def Bias(data, period=6):\n",
    "    MA = data['Close'].rolling(window=period).mean()\n",
    "    bias=[]\n",
    "    for i in range(len(data)):\n",
    "        bias.append(((data['Close'][i]-MA[i])/MA[i])*100)\n",
    "    return pd.DataFrame(bias, columns=['Bias'])\n",
    "def PSY(data, period=12):\n",
    "    psy = [np.nan]*(period-1)\n",
    "    for i in range(len(data)-period+1):\n",
    "        diff = np.ediff1d(data['Close'][i:i+period])\n",
    "        psy.append((len(diff[diff>=0])/len(diff))*100)\n",
    "    return pd.DataFrame(psy, columns=['PSY'])\n",
    "def SY(data, i, p):\n",
    "    return ((data['Close'][i-p]-data['Close'][i-p-1])/data['Close'][i-p-1])*100\n",
    "\n",
    "def ASY(data, period):\n",
    "    if period == 1:\n",
    "        asy = [np.nan]*2\n",
    "        for i in range(2,len(data)):\n",
    "            asy.append(((data['Close'][i-1]-data['Close'][i-2])/data['Close'][i-2])*100)\n",
    "    else:\n",
    "        asy = [np.nan]*period\n",
    "        for i in range(period,len(data)):\n",
    "            A=0\n",
    "            for j in range(period):\n",
    "                A = A + SY(data, i,j)\n",
    "            A = A/(j+1)\n",
    "            asy.append(A)\n",
    "            \n",
    "    return pd.DataFrame(asy, columns=['ASY'+str(period)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aalahgholipour160413\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from stockstats import StockDataFrame\n",
    "indicators = ['close_50_sma','close_150_sma','close_20_ema','close_40_ema','boll','boll_ub','boll_lb',\\\n",
    "             'macd','kdjk','kdjd','kdjj','atr','adx','vr','rsi_14']\n",
    "for i in indicators:\n",
    "    df = StockDataFrame.retype(data)\n",
    "    df = df.get(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4302, 7)\n",
      "(4302, 7)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.replace([np.inf, -np.inf], np.nan)\n",
    "data = data.dropna()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff=np.ediff1d(data.iloc[:,3])\n",
    "diff.shape\n",
    "Data = np.append(data.values[:-1,:], diff.reshape(-1,1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4299, 57)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aalahgholipour160413\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#values = data[['Weighted'] + ['Volume (BTC)'] + ['Volume (Currency)']].values\n",
    "values = data[['Open'] + ['High'] + ['Low'] + ['Close'] + ['Volume']]\n",
    "# values.insert(5,'OBV',OBV(data))\n",
    "# #values.insert(2,'Volume',data['Volume'])#.rolling(window=50).mean())\n",
    "# values.insert(6,'MA5',data['Close'].rolling(window=5).mean())\n",
    "# values.insert(7,'Bias',Bias(data,6))\n",
    "# values.insert(8,'PSY12',PSY(data,12))\n",
    "# values.insert(9,'ASY1',ASY(data,1))\n",
    "# values.insert(10,'ASY2',ASY(data,2))\n",
    "# values.insert(11,'ASY3',ASY(data,3))\n",
    "# values.insert(12,'ASY4',ASY(data,4))\n",
    "# values.insert(13,'ASY5',ASY(data,5))\n",
    "# diff = np.ediff1d(data['Close'])\n",
    "# diff=np.append(np.array([0]),diff)\n",
    "# values.insert(14,'diff',diff)\n",
    "#values.insert(4,'MA150',data['Close'].rolling(window=150).mean())\n",
    "#values.insert(5, 'EMA20', data['Close'].ewm(span=20, adjust=False).mean())\n",
    "#values.insert(13, 'Lower', Lower)\n",
    "#values.insert(14, 'Avg', Avg)\n",
    "#values.insert(15, 'Upper', Upper)\n",
    "#values.insert(5,'open', data['Open'])\n",
    "#values=values.iloc[:,1:]\n",
    "values.dropna(inplace=True)\n",
    "#values=values.values\n",
    "values = values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>OBV</th>\n",
       "      <th>MA5</th>\n",
       "      <th>Bias</th>\n",
       "      <th>PSY12</th>\n",
       "      <th>ASY1</th>\n",
       "      <th>ASY2</th>\n",
       "      <th>ASY3</th>\n",
       "      <th>ASY4</th>\n",
       "      <th>ASY5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.723571</td>\n",
       "      <td>1.786429</td>\n",
       "      <td>1.702857</td>\n",
       "      <td>1.775000</td>\n",
       "      <td>113685600.0</td>\n",
       "      <td>244389600.0</td>\n",
       "      <td>1.651286</td>\n",
       "      <td>8.341811</td>\n",
       "      <td>54.545456</td>\n",
       "      <td>8.074534</td>\n",
       "      <td>5.043014</td>\n",
       "      <td>5.569515</td>\n",
       "      <td>2.459068</td>\n",
       "      <td>2.575527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.777143</td>\n",
       "      <td>1.792857</td>\n",
       "      <td>1.707857</td>\n",
       "      <td>1.711429</td>\n",
       "      <td>69666800.0</td>\n",
       "      <td>174722800.0</td>\n",
       "      <td>1.669286</td>\n",
       "      <td>3.016857</td>\n",
       "      <td>45.454544</td>\n",
       "      <td>2.011494</td>\n",
       "      <td>-0.784985</td>\n",
       "      <td>2.168188</td>\n",
       "      <td>3.281770</td>\n",
       "      <td>1.250962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.712857</td>\n",
       "      <td>1.801429</td>\n",
       "      <td>1.643571</td>\n",
       "      <td>1.792857</td>\n",
       "      <td>161957600.0</td>\n",
       "      <td>336680384.0</td>\n",
       "      <td>1.725857</td>\n",
       "      <td>6.093684</td>\n",
       "      <td>54.545456</td>\n",
       "      <td>-3.581465</td>\n",
       "      <td>0.588215</td>\n",
       "      <td>1.062642</td>\n",
       "      <td>2.815615</td>\n",
       "      <td>3.576995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.555714</td>\n",
       "      <td>1.627143</td>\n",
       "      <td>1.458571</td>\n",
       "      <td>1.485000</td>\n",
       "      <td>284253184.0</td>\n",
       "      <td>52427200.0</td>\n",
       "      <td>1.700857</td>\n",
       "      <td>-11.906782</td>\n",
       "      <td>45.454544</td>\n",
       "      <td>4.757895</td>\n",
       "      <td>-6.206707</td>\n",
       "      <td>-5.331626</td>\n",
       "      <td>-3.495846</td>\n",
       "      <td>-1.181770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.516429</td>\n",
       "      <td>1.530000</td>\n",
       "      <td>1.410714</td>\n",
       "      <td>1.425714</td>\n",
       "      <td>215284992.0</td>\n",
       "      <td>-162857792.0</td>\n",
       "      <td>1.638000</td>\n",
       "      <td>-13.854139</td>\n",
       "      <td>45.454544</td>\n",
       "      <td>-17.171309</td>\n",
       "      <td>-10.581816</td>\n",
       "      <td>-5.468579</td>\n",
       "      <td>-4.996800</td>\n",
       "      <td>-3.595141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Open      High       Low     Close       Volume          OBV  \\\n",
       "11  1.723571  1.786429  1.702857  1.775000  113685600.0  244389600.0   \n",
       "12  1.777143  1.792857  1.707857  1.711429   69666800.0  174722800.0   \n",
       "13  1.712857  1.801429  1.643571  1.792857  161957600.0  336680384.0   \n",
       "14  1.555714  1.627143  1.458571  1.485000  284253184.0   52427200.0   \n",
       "15  1.516429  1.530000  1.410714  1.425714  215284992.0 -162857792.0   \n",
       "\n",
       "         MA5       Bias      PSY12       ASY1       ASY2      ASY3      ASY4  \\\n",
       "11  1.651286   8.341811  54.545456   8.074534   5.043014  5.569515  2.459068   \n",
       "12  1.669286   3.016857  45.454544   2.011494  -0.784985  2.168188  3.281770   \n",
       "13  1.725857   6.093684  54.545456  -3.581465   0.588215  1.062642  2.815615   \n",
       "14  1.700857 -11.906782  45.454544   4.757895  -6.206707 -5.331626 -3.495846   \n",
       "15  1.638000 -13.854139  45.454544 -17.171309 -10.581816 -5.468579 -4.996800   \n",
       "\n",
       "        ASY5  \n",
       "11  2.575527  \n",
       "12  1.250962  \n",
       "13  3.576995  \n",
       "14 -1.181770  \n",
       "15 -3.595141  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#values = data.iloc[1:,:]\n",
    "values = values.values\n",
    "#values = Data\n",
    "#values = values[~np.isnan(values).any(axis=1)]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(values)\n",
    "scaled = scaler.transform(values)\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(values)\n",
    "#scaled = scaler.transform(values)\n",
    "#scaled = normalize(values, norm='l2',axis=0)\n",
    "#scaled = scale(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = (values.values[:-1,:]/values.values[1:,:])\n",
    "scaled = pd.DataFrame(scaled)\n",
    "#scaled.replace([np.inf, -np.inf], np.nan)\n",
    "#scaled = scaled.dropna()\n",
    "all_inf_or_nan = scaled.isin([np.inf, -np.inf, np.nan]).all(axis='columns')\n",
    "scaled = scaled[~all_inf_or_nan]\n",
    "scaled = scaled.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(scaled[:,3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25725883,  0.24984172,  0.25506976,  0.2482361 ,  0.13409345], dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4291, 14)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3994, 5, 11) (3994,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((147, 5, 11), (147,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.utils import shuffle\n",
    "data_gen = TimeseriesGenerator(scaled[:4000], scaled[:4000,-1],\n",
    "                               length=5, sampling_rate=1,\n",
    "                               stride=1, batch_size=len(scaled[:4000]))\n",
    "X, y = data_gen[0]\n",
    "#X, y = shuffle(X, y, random_state = 0)\n",
    "print(X.shape, y.shape)\n",
    "data_gen2 = TimeseriesGenerator(scaled[4000:], scaled[4000:,-1],\n",
    "                               length=5, sampling_rate=1,\n",
    "                               stride=1, batch_size=len(scaled[4000:]),shuffle=False)\n",
    "test_X, test_y = data_gen2[0]\n",
    "#test_X, test_y = shuffle(test_X, test_y, random_state = 0)\n",
    "test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3999,)\n",
      "(3993, 5)\n",
      "(152,)\n",
      "(146, 5)\n"
     ]
    }
   ],
   "source": [
    "y = np.ediff1d(scaled[:4000,-1])\n",
    "print(y.shape)\n",
    "data_gen = TimeseriesGenerator(y, y,\n",
    "                               length=5, sampling_rate=1,\n",
    "                               stride=1, batch_size=len(scaled[:4000]))\n",
    "y_seq,_ = data_gen[0]\n",
    "print(y_seq.shape)\n",
    "\n",
    "test_y = np.ediff1d(scaled[4000:,-1])\n",
    "print(test_y.shape)\n",
    "data_gen = TimeseriesGenerator(test_y, test_y,\n",
    "                               length=5, sampling_rate=1,\n",
    "                               stride=1, batch_size=len(scaled[4000:]))\n",
    "test_y_seq,_ = data_gen[0]\n",
    "print(test_y_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3958, 40, 11) (3958, 40)\n",
      "(111, 40, 11) (111, 40)\n"
     ]
    }
   ],
   "source": [
    "#y = np.ediff1d(scaled[19:4000,-1])\n",
    "y=y_seq\n",
    "X = X[:-1]\n",
    "#y = y[:-(len(y)-len(X))]\n",
    "y1 = np.empty([len(y),y.shape[1]], dtype=np.float32)\n",
    "for i in range(len(y)):\n",
    "    for j in range(y.shape[1]):\n",
    "        if y[i,j] >= 0:\n",
    "            y1[i,j] = 1.0\n",
    "        else:\n",
    "            y1[i,j] = 0.0\n",
    "print(X.shape, y1.shape)\n",
    "\n",
    "#test_y = np.ediff1d(scaled[4019:,-1])\n",
    "test_y=test_y_seq\n",
    "test_X = test_X[:-1]\n",
    "#test_y = test_y[:-(len(test_y)-len(test_X))]\n",
    "test_y1 = np.empty([len(test_y),test_y.shape[1]], dtype=np.float32)\n",
    "for i in range(len(test_y)):\n",
    "    for j in range(test_y.shape[1]):\n",
    "        if test_y[i,j] >= 0:\n",
    "            test_y1[i,j] = 1.0\n",
    "        else:\n",
    "            test_y1[i,j] = 0.0\n",
    "print(test_X.shape, test_y1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sequence and then train valid and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.90603629e-05,  -1.00138597e-04,   2.24443153e-04, ...,\n",
       "         5.41905165e-02,   3.04549336e-02,  -1.00000000e+00])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.ediff1d(s[:,3])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4303, 5)\n",
      "(4302, 5)\n"
     ]
    }
   ],
   "source": [
    "s=np.append(scaled, np.zeros((1,scaled.shape[1])),axis=0)\n",
    "print(s.shape)\n",
    "print(scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4275, 25, 5) (4275,)\n",
      "(4300,)\n",
      "(4274,)\n",
      "(4274, 25, 5) (4274,)\n",
      "(4274,)\n",
      "(4274, 2)\n",
      "(4254, 25, 5) (4254, 2) (300, 25, 5) (300, 2) (20, 25, 5) (20, 2)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.utils import shuffle\n",
    "#scaled=values\n",
    "scaled2=scaled.copy()\n",
    "#scaled=scaled[:-15]\n",
    "s=np.append(scaled, np.zeros((1,scaled.shape[1])),axis=0)\n",
    "data_gen = TimeseriesGenerator(scaled[:], scaled[:,3],\n",
    "                               length=15, sampling_rate=1,\n",
    "                               stride=1, batch_size=len(s-1))\n",
    "X, y = data_gen[0]\n",
    "print(X.shape, y.shape)\n",
    "y = np.ediff1d(scaled[:,3])\n",
    "print(y.shape)\n",
    "data_gen = TimeseriesGenerator(y, y,\n",
    "                              length=15, sampling_rate=1,\n",
    "                              stride=1, batch_size=len(y))\n",
    "_, y_seq = data_gen[0]\n",
    "print(y_seq.shape)\n",
    "y=y_seq\n",
    "X = X[:-1]\n",
    "print(X.shape, y.shape)\n",
    "y1 = np.empty([len(y)], dtype=np.float32)\n",
    "for i in range(len(y)):\n",
    "    if y[i] >= 0.0:\n",
    "        y1[i] = 1.0\n",
    "    else:\n",
    "        y1[i] = 0.0\n",
    "\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "print(y1.shape)\n",
    "#y1=y1[:,-1]\n",
    "y1=to_categorical(y1)\n",
    "print(y1.shape)\n",
    "# scaler = StandardScaler()\n",
    "#scaler.fit(y.reshape(-1, 1))\n",
    "#y1 = scaler.transform(y.reshape(-1, 1))\n",
    "# #y1 = scale(y)\n",
    "# print(X.shape, y1.shape)\n",
    "#y1=y1*20\n",
    "#y1=y\n",
    "#X, y1 = shuffle(X, y1, random_state = 0)\n",
    "train_X = X[:-20]\n",
    "train_y = y1[:-20]\n",
    "train_X, train_y = shuffle(train_X, train_y, random_state = 1)\n",
    "valid_X = X[3500:3800]\n",
    "valid_y = y1[3500:3800]\n",
    "test_X = X[-20:]\n",
    "test_y = y1[-20:]\n",
    "print(train_X.shape, train_y.shape, valid_X.shape, valid_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4281, 75)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.reshape(4281,75).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=80, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=250, max_depth=80,random_state=0)\n",
    "clf.fit(train_X.reshape(4281,75), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  1.], dtype=float32)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(test_X.reshape(3,75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "plt.hist(to_categorical(y1)[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4127, 15, 56) (4127,)\n"
     ]
    }
   ],
   "source": [
    "# X = scaled[:14].reshape(1,14,8)\n",
    "# y = scaled[28,-1]\n",
    "# for i in range(1,500):\n",
    "#     if 14*(i+2)<len(scaled):\n",
    "#         X = np.append(X, scaled[(14*(i)):(14*(i+1)),:].reshape(1,14,8), axis=0)\n",
    "#         y = np.append(y, scaled[14*(i+2),-1])\n",
    "# X.shape, y.shape\n",
    "#scaled2=scaled\n",
    "#scaled=scaled[:-15]\n",
    "X = scaled[-16:-1,:].reshape(1,15,56)\n",
    "y = scaled[-1,3]-scaled[-2,3]\n",
    "for i in range(1,4127):\n",
    "    X = np.append(X, scaled[-16-i:-1-i,:].reshape(1,15,56),axis=0)\n",
    "    y = np.append(y, scaled[-1-i,3]-scaled[-2-i,3])\n",
    "y1 = np.empty([len(y)], dtype=np.float32)\n",
    "for i in range(len(y)):\n",
    "    if y[i] >= 0:\n",
    "        y1[i] = 1.0\n",
    "    else:\n",
    "        y1[i] = -1.0\n",
    "print(X.shape,y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4204, 14) (4204,) (86, 14) (86,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(scaled[:,:-1], scaled[:,-1], test_size=0.02, shuffle=False)\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, y1 = shuffle(X, y1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.empty([len(y)], dtype=np.float32)\n",
    "for i in range(len(y)):\n",
    "    if y[i] >= 0:\n",
    "        y1[i] = 1.0\n",
    "    else:\n",
    "        y1[i] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4254/4254 [==============================] - 20s 5ms/step - loss: 0.7844 - acc: 0.5035\n",
      "Epoch 2/50\n",
      "4254/4254 [==============================] - 4s 879us/step - loss: 0.7207 - acc: 0.5160\n",
      "Epoch 3/50\n",
      "4254/4254 [==============================] - 4s 888us/step - loss: 0.7033 - acc: 0.5336\n",
      "Epoch 4/50\n",
      "4254/4254 [==============================] - 4s 880us/step - loss: 0.7018 - acc: 0.5219\n",
      "Epoch 5/50\n",
      "4254/4254 [==============================] - 4s 884us/step - loss: 0.6959 - acc: 0.5378\n",
      "Epoch 6/50\n",
      "4254/4254 [==============================] - 4s 882us/step - loss: 0.6944 - acc: 0.5435\n",
      "Epoch 7/50\n",
      "4254/4254 [==============================] - 4s 879us/step - loss: 0.6899 - acc: 0.5531\n",
      "Epoch 8/50\n",
      "4254/4254 [==============================] - 4s 872us/step - loss: 0.6949 - acc: 0.5383\n",
      "Epoch 9/50\n",
      "4254/4254 [==============================] - 4s 895us/step - loss: 0.6924 - acc: 0.5442\n",
      "Epoch 10/50\n",
      "4254/4254 [==============================] - 4s 882us/step - loss: 0.6898 - acc: 0.5456\n",
      "Epoch 11/50\n",
      "4254/4254 [==============================] - 4s 873us/step - loss: 0.6856 - acc: 0.5588\n",
      "Epoch 12/50\n",
      "4254/4254 [==============================] - 4s 883us/step - loss: 0.6829 - acc: 0.5689\n",
      "Epoch 13/50\n",
      "4254/4254 [==============================] - 4s 882us/step - loss: 0.6851 - acc: 0.5480\n",
      "Epoch 14/50\n",
      "4254/4254 [==============================] - 4s 879us/step - loss: 0.6817 - acc: 0.5581\n",
      "Epoch 15/50\n",
      "4254/4254 [==============================] - 4s 877us/step - loss: 0.6820 - acc: 0.5599\n",
      "Epoch 16/50\n",
      "4254/4254 [==============================] - 4s 878us/step - loss: 0.6806 - acc: 0.5689\n",
      "Epoch 17/50\n",
      "4254/4254 [==============================] - 4s 885us/step - loss: 0.6755 - acc: 0.5743\n",
      "Epoch 18/50\n",
      "4254/4254 [==============================] - 4s 896us/step - loss: 0.6787 - acc: 0.5559\n",
      "Epoch 19/50\n",
      "4254/4254 [==============================] - 4s 907us/step - loss: 0.6725 - acc: 0.5849\n",
      "Epoch 20/50\n",
      "4254/4254 [==============================] - 4s 922us/step - loss: 0.6739 - acc: 0.5757\n",
      "Epoch 21/50\n",
      "4254/4254 [==============================] - 4s 899us/step - loss: 0.6701 - acc: 0.5863\n",
      "Epoch 22/50\n",
      "4254/4254 [==============================] - 4s 901us/step - loss: 0.6710 - acc: 0.5856\n",
      "Epoch 23/50\n",
      "4254/4254 [==============================] - 4s 885us/step - loss: 0.6680 - acc: 0.5886\n",
      "Epoch 24/50\n",
      "4254/4254 [==============================] - 4s 902us/step - loss: 0.6676 - acc: 0.5863\n",
      "Epoch 25/50\n",
      "4254/4254 [==============================] - 4s 896us/step - loss: 0.6673 - acc: 0.5830\n",
      "Epoch 26/50\n",
      "4254/4254 [==============================] - 4s 901us/step - loss: 0.6625 - acc: 0.5976\n",
      "Epoch 27/50\n",
      "4254/4254 [==============================] - 4s 876us/step - loss: 0.6641 - acc: 0.5938\n",
      "Epoch 28/50\n",
      "4254/4254 [==============================] - 4s 896us/step - loss: 0.6635 - acc: 0.5983\n",
      "Epoch 29/50\n",
      "4254/4254 [==============================] - 4s 872us/step - loss: 0.6625 - acc: 0.5983\n",
      "Epoch 30/50\n",
      "4254/4254 [==============================] - 4s 876us/step - loss: 0.6591 - acc: 0.5933\n",
      "Epoch 31/50\n",
      "4254/4254 [==============================] - 4s 888us/step - loss: 0.6561 - acc: 0.6030\n",
      "Epoch 32/50\n",
      "4254/4254 [==============================] - 4s 869us/step - loss: 0.6556 - acc: 0.5992\n",
      "Epoch 33/50\n",
      "4254/4254 [==============================] - 4s 873us/step - loss: 0.6576 - acc: 0.6039\n",
      "Epoch 34/50\n",
      "4254/4254 [==============================] - 4s 890us/step - loss: 0.6557 - acc: 0.6095\n",
      "Epoch 35/50\n",
      "4254/4254 [==============================] - 4s 888us/step - loss: 0.6470 - acc: 0.6157\n",
      "Epoch 36/50\n",
      "4254/4254 [==============================] - 4s 865us/step - loss: 0.6490 - acc: 0.6168\n",
      "Epoch 37/50\n",
      "4254/4254 [==============================] - 4s 866us/step - loss: 0.6465 - acc: 0.6124\n",
      "Epoch 38/50\n",
      "4254/4254 [==============================] - 4s 867us/step - loss: 0.6402 - acc: 0.6279\n",
      "Epoch 39/50\n",
      "4254/4254 [==============================] - 4s 867us/step - loss: 0.6441 - acc: 0.6199\n",
      "Epoch 40/50\n",
      "4254/4254 [==============================] - 4s 864us/step - loss: 0.6385 - acc: 0.6331\n",
      "Epoch 41/50\n",
      "4254/4254 [==============================] - 4s 874us/step - loss: 0.6312 - acc: 0.6425\n",
      "Epoch 42/50\n",
      "4254/4254 [==============================] - 4s 875us/step - loss: 0.6341 - acc: 0.6417\n",
      "Epoch 43/50\n",
      "4254/4254 [==============================] - 4s 864us/step - loss: 0.6283 - acc: 0.6307\n",
      "Epoch 44/50\n",
      "4254/4254 [==============================] - 4s 864us/step - loss: 0.6237 - acc: 0.6382\n",
      "Epoch 45/50\n",
      "4254/4254 [==============================] - 4s 869us/step - loss: 0.6243 - acc: 0.6434\n",
      "Epoch 46/50\n",
      "4254/4254 [==============================] - 4s 867us/step - loss: 0.6270 - acc: 0.6399\n",
      "Epoch 47/50\n",
      "4254/4254 [==============================] - 4s 873us/step - loss: 0.6261 - acc: 0.6410\n",
      "Epoch 48/50\n",
      "4254/4254 [==============================] - 4s 862us/step - loss: 0.6209 - acc: 0.6441\n",
      "Epoch 49/50\n",
      "4254/4254 [==============================] - 4s 866us/step - loss: 0.6262 - acc: 0.6483\n",
      "Epoch 50/50\n",
      "4254/4254 [==============================] - 4s 876us/step - loss: 0.6189 - acc: 0.6596\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import metrics\n",
    "from keras.initializers import he_normal, lecun_normal\n",
    "from keras.layers import Activation\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "def custom_activation(x):\n",
    "    return (K.sigmoid(x*10)) \n",
    "\n",
    "get_custom_objects().update({'custom_activation': Activation(custom_activation)})\n",
    "\n",
    "def tcn(h,filters=500, kernel_size=3, padding='causal', activation='relu', dilation_rate=1):\n",
    "    main = BatchNormalization()(h)\n",
    "    main = h\n",
    "    init = lecun_normal(seed=1)\n",
    "    for i in range(1):\n",
    "        main = Conv1D(filters=filters,kernel_size=kernel_size,padding=padding, dilation_rate=dilation_rate, kernel_initializer=init)(main)\n",
    "        main = Activation('relu')(main)\n",
    "        main = BatchNormalization()(main)       \n",
    "        main = Dropout(0.25)(main)\n",
    "    side_path = Conv1D(filters=filters,kernel_size=1, padding='same', kernel_initializer=init)(h)\n",
    "    #side_path = BatchNormalization()(side_path)\n",
    "    return Add()([main,side_path])\n",
    "\n",
    "Inp = Input(shape=(15,5))\n",
    "inp = Inp\n",
    "D = [1,2,4,1,1]\n",
    "for i in range(3):\n",
    "    inp=tcn(inp,dilation_rate=D[i])\n",
    "    #inp = BatchNormalization()(inp)\n",
    "    #inp = Activation('relu')(inp)\n",
    "inp=Flatten()(inp)\n",
    "init = lecun_normal(seed=1)\n",
    "inp=Dense(100)(inp)\n",
    "inp = Activation('relu')(inp)\n",
    "inp = BatchNormalization()(inp)\n",
    "inp = Dropout(0.25)(inp)\n",
    "inp=Dense(10)(inp)\n",
    "inp = Activation('relu')(inp)\n",
    "inp = BatchNormalization()(inp)\n",
    "#inp = Dropout(0.25)(inp)\n",
    "out=Dense(2,activation='softmax')(inp)\n",
    "#inp = Lambda(lambda x: x * 2)(inp)\n",
    "#inp = Lambda(lambda x: x/100)(inp)\n",
    "model = Model(Inp,out)\n",
    "ad = optimizers.Adam(lr=0.001)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=5, min_lr=1e-8)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=ad, metrics=['accuracy'])\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=128, verbose=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3784 samples, validate on 421 samples\n",
      "Epoch 1/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6903 - acc: 0.5285 - val_loss: 0.6915 - val_acc: 0.5392\n",
      "Epoch 2/1000\n",
      "3784/3784 [==============================] - 1s 237us/step - loss: 0.6910 - acc: 0.5280 - val_loss: 0.6910 - val_acc: 0.5416\n",
      "Epoch 3/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.6894 - acc: 0.5254 - val_loss: 0.6906 - val_acc: 0.5487\n",
      "Epoch 4/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6894 - acc: 0.5262 - val_loss: 0.6916 - val_acc: 0.5368\n",
      "Epoch 5/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6895 - acc: 0.5307 - val_loss: 0.6916 - val_acc: 0.5321\n",
      "Epoch 6/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6910 - acc: 0.5246 - val_loss: 0.6917 - val_acc: 0.5321\n",
      "Epoch 7/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6923 - acc: 0.5206 - val_loss: 0.6906 - val_acc: 0.5392\n",
      "Epoch 8/1000\n",
      "3784/3784 [==============================] - 1s 241us/step - loss: 0.6892 - acc: 0.5312 - val_loss: 0.6905 - val_acc: 0.5392\n",
      "Epoch 9/1000\n",
      "3784/3784 [==============================] - 1s 251us/step - loss: 0.6892 - acc: 0.5288 - val_loss: 0.6901 - val_acc: 0.5392\n",
      "Epoch 10/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.6910 - acc: 0.5270 - val_loss: 0.6898 - val_acc: 0.5392\n",
      "Epoch 11/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6895 - acc: 0.5235 - val_loss: 0.6895 - val_acc: 0.5392\n",
      "Epoch 12/1000\n",
      "3784/3784 [==============================] - 1s 251us/step - loss: 0.6890 - acc: 0.5272 - val_loss: 0.6903 - val_acc: 0.5392\n",
      "Epoch 13/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6911 - acc: 0.5246 - val_loss: 0.6903 - val_acc: 0.5392\n",
      "Epoch 14/1000\n",
      "3784/3784 [==============================] - 1s 237us/step - loss: 0.6907 - acc: 0.5262 - val_loss: 0.6904 - val_acc: 0.5416\n",
      "Epoch 15/1000\n",
      "3784/3784 [==============================] - 1s 237us/step - loss: 0.6901 - acc: 0.5291 - val_loss: 0.6903 - val_acc: 0.5392\n",
      "Epoch 16/1000\n",
      "3784/3784 [==============================] - 1s 237us/step - loss: 0.6915 - acc: 0.5254 - val_loss: 0.6894 - val_acc: 0.5487\n",
      "Epoch 17/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6887 - acc: 0.5299 - val_loss: 0.6900 - val_acc: 0.5392\n",
      "Epoch 18/1000\n",
      "3784/3784 [==============================] - 1s 245us/step - loss: 0.6883 - acc: 0.5277 - val_loss: 0.6901 - val_acc: 0.5416\n",
      "Epoch 19/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.6882 - acc: 0.5307 - val_loss: 0.6922 - val_acc: 0.5344\n",
      "Epoch 20/1000\n",
      "3784/3784 [==============================] - 1s 245us/step - loss: 0.6898 - acc: 0.5283 - val_loss: 0.6911 - val_acc: 0.5368\n",
      "Epoch 21/1000\n",
      "3784/3784 [==============================] - 1s 237us/step - loss: 0.6903 - acc: 0.5243 - val_loss: 0.6910 - val_acc: 0.5392\n",
      "Epoch 22/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.6908 - acc: 0.5238 - val_loss: 0.6910 - val_acc: 0.5368\n",
      "Epoch 23/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6915 - acc: 0.5235 - val_loss: 0.6905 - val_acc: 0.5392\n",
      "Epoch 24/1000\n",
      "3784/3784 [==============================] - 1s 249us/step - loss: 0.6877 - acc: 0.5285 - val_loss: 0.6905 - val_acc: 0.5416\n",
      "Epoch 25/1000\n",
      "3784/3784 [==============================] - 1s 238us/step - loss: 0.6886 - acc: 0.5248 - val_loss: 0.6917 - val_acc: 0.5392\n",
      "Epoch 26/1000\n",
      "3784/3784 [==============================] - 1s 237us/step - loss: 0.6897 - acc: 0.5251 - val_loss: 0.6916 - val_acc: 0.5392\n",
      "Epoch 27/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6866 - acc: 0.5262 - val_loss: 0.6918 - val_acc: 0.5392\n",
      "Epoch 28/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.6893 - acc: 0.5275 - val_loss: 0.6918 - val_acc: 0.5392\n",
      "Epoch 29/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.6890 - acc: 0.5277 - val_loss: 0.6926 - val_acc: 0.5392\n",
      "Epoch 30/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6888 - acc: 0.5285 - val_loss: 0.6928 - val_acc: 0.5392\n",
      "Epoch 31/1000\n",
      "3784/3784 [==============================] - 1s 237us/step - loss: 0.6890 - acc: 0.5217 - val_loss: 0.6932 - val_acc: 0.5344\n",
      "Epoch 32/1000\n",
      "3784/3784 [==============================] - 1s 250us/step - loss: 0.6881 - acc: 0.5309 - val_loss: 0.6936 - val_acc: 0.5392\n",
      "Epoch 33/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6879 - acc: 0.5296 - val_loss: 0.6928 - val_acc: 0.5344\n",
      "Epoch 34/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6903 - acc: 0.5280 - val_loss: 0.6937 - val_acc: 0.5344\n",
      "Epoch 35/1000\n",
      "3784/3784 [==============================] - 1s 246us/step - loss: 0.6877 - acc: 0.5251 - val_loss: 0.6928 - val_acc: 0.5368\n",
      "Epoch 36/1000\n",
      "3784/3784 [==============================] - 1s 244us/step - loss: 0.6900 - acc: 0.5270 - val_loss: 0.6921 - val_acc: 0.5392\n",
      "Epoch 37/1000\n",
      "3784/3784 [==============================] - 1s 248us/step - loss: 0.6879 - acc: 0.5272 - val_loss: 0.6929 - val_acc: 0.5392\n",
      "Epoch 38/1000\n",
      "3784/3784 [==============================] - 1s 254us/step - loss: 0.6869 - acc: 0.5307 - val_loss: 0.6947 - val_acc: 0.5392\n",
      "Epoch 39/1000\n",
      "3784/3784 [==============================] - 1s 237us/step - loss: 0.6889 - acc: 0.5312 - val_loss: 0.6935 - val_acc: 0.5392\n",
      "Epoch 40/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6896 - acc: 0.5325 - val_loss: 0.6927 - val_acc: 0.5392\n",
      "Epoch 41/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6894 - acc: 0.5235 - val_loss: 0.6936 - val_acc: 0.5344\n",
      "Epoch 42/1000\n",
      "3784/3784 [==============================] - 1s 237us/step - loss: 0.6882 - acc: 0.5275 - val_loss: 0.6944 - val_acc: 0.5321\n",
      "Epoch 43/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.6878 - acc: 0.5336 - val_loss: 0.6938 - val_acc: 0.5344\n",
      "Epoch 44/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6877 - acc: 0.5312 - val_loss: 0.6949 - val_acc: 0.5249\n",
      "Epoch 45/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.6868 - acc: 0.5280 - val_loss: 0.6937 - val_acc: 0.5368\n",
      "Epoch 46/1000\n",
      "3784/3784 [==============================] - 1s 242us/step - loss: 0.6860 - acc: 0.5346 - val_loss: 0.6935 - val_acc: 0.5416\n",
      "Epoch 47/1000\n",
      "3784/3784 [==============================] - 1s 238us/step - loss: 0.6881 - acc: 0.5317 - val_loss: 0.6947 - val_acc: 0.5463\n",
      "Epoch 48/1000\n",
      "3784/3784 [==============================] - 1s 243us/step - loss: 0.6866 - acc: 0.5314 - val_loss: 0.6937 - val_acc: 0.5273\n",
      "Epoch 49/1000\n",
      "3784/3784 [==============================] - 1s 244us/step - loss: 0.6880 - acc: 0.5333 - val_loss: 0.6943 - val_acc: 0.5321\n",
      "Epoch 50/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.6896 - acc: 0.5299 - val_loss: 0.6952 - val_acc: 0.5321\n",
      "Epoch 51/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6858 - acc: 0.5288 - val_loss: 0.6944 - val_acc: 0.5392\n",
      "Epoch 52/1000\n",
      "3784/3784 [==============================] - 1s 237us/step - loss: 0.6834 - acc: 0.5325 - val_loss: 0.6960 - val_acc: 0.5321\n",
      "Epoch 53/1000\n",
      "3784/3784 [==============================] - ETA: 0s - loss: 0.6863 - acc: 0.536 - 1s 240us/step - loss: 0.6859 - acc: 0.5378 - val_loss: 0.6972 - val_acc: 0.5368\n",
      "Epoch 54/1000\n",
      "3784/3784 [==============================] - 1s 252us/step - loss: 0.6869 - acc: 0.5270 - val_loss: 0.6957 - val_acc: 0.5463\n",
      "Epoch 55/1000\n",
      "3784/3784 [==============================] - 1s 243us/step - loss: 0.6850 - acc: 0.5378 - val_loss: 0.6953 - val_acc: 0.5392\n",
      "Epoch 56/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6847 - acc: 0.5330 - val_loss: 0.6946 - val_acc: 0.5368\n",
      "Epoch 57/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6853 - acc: 0.5314 - val_loss: 0.6972 - val_acc: 0.5344\n",
      "Epoch 58/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6853 - acc: 0.5381 - val_loss: 0.6978 - val_acc: 0.5416\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.6826 - acc: 0.5404 - val_loss: 0.6995 - val_acc: 0.5416\n",
      "Epoch 60/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6873 - acc: 0.5349 - val_loss: 0.6973 - val_acc: 0.5321\n",
      "Epoch 61/1000\n",
      "3784/3784 [==============================] - 1s 240us/step - loss: 0.6830 - acc: 0.5314 - val_loss: 0.6939 - val_acc: 0.5463\n",
      "Epoch 62/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.6860 - acc: 0.5391 - val_loss: 0.6924 - val_acc: 0.5439\n",
      "Epoch 63/1000\n",
      "3784/3784 [==============================] - 1s 239us/step - loss: 0.6838 - acc: 0.5375 - val_loss: 0.6929 - val_acc: 0.5416\n",
      "Epoch 64/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.6827 - acc: 0.5330 - val_loss: 0.6967 - val_acc: 0.5368\n",
      "Epoch 65/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6875 - acc: 0.5322 - val_loss: 0.6957 - val_acc: 0.5439\n",
      "Epoch 66/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6860 - acc: 0.5256 - val_loss: 0.6961 - val_acc: 0.5463\n",
      "Epoch 67/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6819 - acc: 0.5367 - val_loss: 0.6952 - val_acc: 0.5439\n",
      "Epoch 68/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6857 - acc: 0.5333 - val_loss: 0.6946 - val_acc: 0.5558\n",
      "Epoch 69/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.6840 - acc: 0.5375 - val_loss: 0.6953 - val_acc: 0.5416\n",
      "Epoch 70/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.6861 - acc: 0.5359 - val_loss: 0.6960 - val_acc: 0.5534\n",
      "Epoch 71/1000\n",
      "3784/3784 [==============================] - 1s 241us/step - loss: 0.6825 - acc: 0.5375 - val_loss: 0.6955 - val_acc: 0.5439\n",
      "Epoch 72/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.6843 - acc: 0.5375 - val_loss: 0.6982 - val_acc: 0.5297\n",
      "Epoch 73/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.6846 - acc: 0.5396 - val_loss: 0.6966 - val_acc: 0.5368\n",
      "Epoch 74/1000\n",
      "3784/3784 [==============================] - 1s 249us/step - loss: 0.6785 - acc: 0.5381 - val_loss: 0.6980 - val_acc: 0.5273\n",
      "Epoch 75/1000\n",
      "3784/3784 [==============================] - 1s 239us/step - loss: 0.6837 - acc: 0.5484 - val_loss: 0.6973 - val_acc: 0.5368\n",
      "Epoch 76/1000\n",
      "3784/3784 [==============================] - 1s 239us/step - loss: 0.6816 - acc: 0.5359 - val_loss: 0.6967 - val_acc: 0.5416\n",
      "Epoch 77/1000\n",
      "3784/3784 [==============================] - 1s 239us/step - loss: 0.6836 - acc: 0.5354 - val_loss: 0.6968 - val_acc: 0.5392\n",
      "Epoch 78/1000\n",
      "3784/3784 [==============================] - 1s 241us/step - loss: 0.6848 - acc: 0.5296 - val_loss: 0.6963 - val_acc: 0.5439\n",
      "Epoch 79/1000\n",
      "3784/3784 [==============================] - 1s 246us/step - loss: 0.6822 - acc: 0.5396 - val_loss: 0.6961 - val_acc: 0.5392\n",
      "Epoch 80/1000\n",
      "3784/3784 [==============================] - 1s 241us/step - loss: 0.6812 - acc: 0.5394 - val_loss: 0.6960 - val_acc: 0.5392\n",
      "Epoch 81/1000\n",
      "3784/3784 [==============================] - 1s 243us/step - loss: 0.6803 - acc: 0.5396 - val_loss: 0.6979 - val_acc: 0.5416\n",
      "Epoch 82/1000\n",
      "3784/3784 [==============================] - 1s 243us/step - loss: 0.6840 - acc: 0.5365 - val_loss: 0.6959 - val_acc: 0.5439\n",
      "Epoch 83/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.6829 - acc: 0.5328 - val_loss: 0.6947 - val_acc: 0.5463\n",
      "Epoch 84/1000\n",
      "3784/3784 [==============================] - 1s 244us/step - loss: 0.6804 - acc: 0.5391 - val_loss: 0.6975 - val_acc: 0.5439\n",
      "Epoch 85/1000\n",
      "3784/3784 [==============================] - 1s 240us/step - loss: 0.6771 - acc: 0.5439 - val_loss: 0.7016 - val_acc: 0.5344\n",
      "Epoch 86/1000\n",
      "3784/3784 [==============================] - 1s 241us/step - loss: 0.6816 - acc: 0.5396 - val_loss: 0.6990 - val_acc: 0.5416\n",
      "Epoch 87/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6791 - acc: 0.5436 - val_loss: 0.6977 - val_acc: 0.5392\n",
      "Epoch 88/1000\n",
      "3784/3784 [==============================] - 1s 239us/step - loss: 0.6776 - acc: 0.5428 - val_loss: 0.6979 - val_acc: 0.5344\n",
      "Epoch 89/1000\n",
      "3784/3784 [==============================] - 1s 247us/step - loss: 0.6784 - acc: 0.5436 - val_loss: 0.6981 - val_acc: 0.5321\n",
      "Epoch 90/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6819 - acc: 0.5388 - val_loss: 0.6978 - val_acc: 0.5344\n",
      "Epoch 91/1000\n",
      "3784/3784 [==============================] - 1s 237us/step - loss: 0.6753 - acc: 0.5452 - val_loss: 0.7003 - val_acc: 0.5416\n",
      "Epoch 92/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.6780 - acc: 0.5436 - val_loss: 0.7006 - val_acc: 0.5368\n",
      "Epoch 93/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6778 - acc: 0.5351 - val_loss: 0.7007 - val_acc: 0.5392\n",
      "Epoch 94/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6776 - acc: 0.5484 - val_loss: 0.6995 - val_acc: 0.5344\n",
      "Epoch 95/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.6774 - acc: 0.5330 - val_loss: 0.7021 - val_acc: 0.5226\n",
      "Epoch 96/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.6745 - acc: 0.5436 - val_loss: 0.7027 - val_acc: 0.5511\n",
      "Epoch 97/1000\n",
      "3784/3784 [==============================] - 1s 237us/step - loss: 0.6749 - acc: 0.5433 - val_loss: 0.7008 - val_acc: 0.5368\n",
      "Epoch 98/1000\n",
      "3784/3784 [==============================] - 1s 238us/step - loss: 0.6766 - acc: 0.5423 - val_loss: 0.6978 - val_acc: 0.5439\n",
      "Epoch 99/1000\n",
      "3784/3784 [==============================] - 1s 247us/step - loss: 0.6798 - acc: 0.5481 - val_loss: 0.7003 - val_acc: 0.5392\n",
      "Epoch 100/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6763 - acc: 0.5441 - val_loss: 0.6985 - val_acc: 0.5392\n",
      "Epoch 101/1000\n",
      "3784/3784 [==============================] - 1s 244us/step - loss: 0.6748 - acc: 0.5526 - val_loss: 0.6979 - val_acc: 0.5392\n",
      "Epoch 102/1000\n",
      "3784/3784 [==============================] - 1s 242us/step - loss: 0.6778 - acc: 0.5423 - val_loss: 0.6988 - val_acc: 0.5368\n",
      "Epoch 103/1000\n",
      "3784/3784 [==============================] - 1s 241us/step - loss: 0.6783 - acc: 0.5468 - val_loss: 0.6999 - val_acc: 0.5416\n",
      "Epoch 104/1000\n",
      "3784/3784 [==============================] - 1s 241us/step - loss: 0.6732 - acc: 0.5431 - val_loss: 0.6976 - val_acc: 0.5344\n",
      "Epoch 105/1000\n",
      "3784/3784 [==============================] - 1s 238us/step - loss: 0.6738 - acc: 0.5481 - val_loss: 0.6948 - val_acc: 0.5511\n",
      "Epoch 106/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.6772 - acc: 0.5462 - val_loss: 0.7017 - val_acc: 0.5558\n",
      "Epoch 107/1000\n",
      "3784/3784 [==============================] - 1s 251us/step - loss: 0.6745 - acc: 0.5449 - val_loss: 0.7012 - val_acc: 0.5558\n",
      "Epoch 108/1000\n",
      "3784/3784 [==============================] - 1s 243us/step - loss: 0.6765 - acc: 0.5439 - val_loss: 0.7003 - val_acc: 0.5439\n",
      "Epoch 109/1000\n",
      "3784/3784 [==============================] - 1s 248us/step - loss: 0.6713 - acc: 0.5468 - val_loss: 0.7059 - val_acc: 0.5368\n",
      "Epoch 110/1000\n",
      "3784/3784 [==============================] - 1s 250us/step - loss: 0.6726 - acc: 0.5563 - val_loss: 0.7098 - val_acc: 0.5297\n",
      "Epoch 111/1000\n",
      "3784/3784 [==============================] - 1s 250us/step - loss: 0.6723 - acc: 0.5465 - val_loss: 0.7050 - val_acc: 0.5273\n",
      "Epoch 112/1000\n",
      "3784/3784 [==============================] - 1s 252us/step - loss: 0.6686 - acc: 0.5523 - val_loss: 0.7059 - val_acc: 0.5321\n",
      "Epoch 113/1000\n",
      "3784/3784 [==============================] - 1s 243us/step - loss: 0.6718 - acc: 0.5484 - val_loss: 0.7044 - val_acc: 0.5297\n",
      "Epoch 114/1000\n",
      "3784/3784 [==============================] - 1s 242us/step - loss: 0.6716 - acc: 0.5455 - val_loss: 0.7043 - val_acc: 0.5226\n",
      "Epoch 115/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6691 - acc: 0.5505 - val_loss: 0.7030 - val_acc: 0.5297\n",
      "Epoch 116/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.6687 - acc: 0.5433 - val_loss: 0.7045 - val_acc: 0.5368\n",
      "Epoch 117/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.6722 - acc: 0.5425 - val_loss: 0.7040 - val_acc: 0.5273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.6699 - acc: 0.5462 - val_loss: 0.7030 - val_acc: 0.5226\n",
      "Epoch 119/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.6675 - acc: 0.5481 - val_loss: 0.7025 - val_acc: 0.5273\n",
      "Epoch 120/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.6744 - acc: 0.5513 - val_loss: 0.7047 - val_acc: 0.5321\n",
      "Epoch 121/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6645 - acc: 0.5579 - val_loss: 0.7063 - val_acc: 0.5297\n",
      "Epoch 122/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6710 - acc: 0.5566 - val_loss: 0.7102 - val_acc: 0.5202\n",
      "Epoch 123/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6643 - acc: 0.5544 - val_loss: 0.7076 - val_acc: 0.5392\n",
      "Epoch 124/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6668 - acc: 0.5507 - val_loss: 0.7092 - val_acc: 0.5273\n",
      "Epoch 125/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.6661 - acc: 0.5539 - val_loss: 0.7110 - val_acc: 0.5178\n",
      "Epoch 126/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.6645 - acc: 0.5610 - val_loss: 0.7132 - val_acc: 0.5226\n",
      "Epoch 127/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.6656 - acc: 0.5502 - val_loss: 0.7138 - val_acc: 0.5154\n",
      "Epoch 128/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6667 - acc: 0.5558 - val_loss: 0.7124 - val_acc: 0.5273\n",
      "Epoch 129/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6688 - acc: 0.5550 - val_loss: 0.7112 - val_acc: 0.5226\n",
      "Epoch 130/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.6640 - acc: 0.5608 - val_loss: 0.7079 - val_acc: 0.5297\n",
      "Epoch 131/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6638 - acc: 0.5542 - val_loss: 0.7086 - val_acc: 0.5368\n",
      "Epoch 132/1000\n",
      "3784/3784 [==============================] - 1s 238us/step - loss: 0.6647 - acc: 0.5621 - val_loss: 0.7105 - val_acc: 0.5321\n",
      "Epoch 133/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6661 - acc: 0.5494 - val_loss: 0.7126 - val_acc: 0.5249\n",
      "Epoch 134/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.6613 - acc: 0.5579 - val_loss: 0.7212 - val_acc: 0.5249\n",
      "Epoch 135/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.6658 - acc: 0.5573 - val_loss: 0.7146 - val_acc: 0.5392\n",
      "Epoch 136/1000\n",
      "3784/3784 [==============================] - 1s 238us/step - loss: 0.6611 - acc: 0.5640 - val_loss: 0.7120 - val_acc: 0.5226\n",
      "Epoch 137/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.6605 - acc: 0.5523 - val_loss: 0.7085 - val_acc: 0.5321\n",
      "Epoch 138/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.6618 - acc: 0.5608 - val_loss: 0.7107 - val_acc: 0.5344\n",
      "Epoch 139/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6578 - acc: 0.5613 - val_loss: 0.7147 - val_acc: 0.5297\n",
      "Epoch 140/1000\n",
      "3784/3784 [==============================] - 1s 242us/step - loss: 0.6574 - acc: 0.5618 - val_loss: 0.7095 - val_acc: 0.5321\n",
      "Epoch 141/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6595 - acc: 0.5711 - val_loss: 0.7086 - val_acc: 0.5321\n",
      "Epoch 142/1000\n",
      "3784/3784 [==============================] - 1s 237us/step - loss: 0.6619 - acc: 0.5584 - val_loss: 0.7097 - val_acc: 0.5154\n",
      "Epoch 143/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6623 - acc: 0.5581 - val_loss: 0.7090 - val_acc: 0.5321\n",
      "Epoch 144/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6641 - acc: 0.5478 - val_loss: 0.7076 - val_acc: 0.5226\n",
      "Epoch 145/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6617 - acc: 0.5571 - val_loss: 0.7128 - val_acc: 0.5297\n",
      "Epoch 146/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6592 - acc: 0.5603 - val_loss: 0.7129 - val_acc: 0.5297\n",
      "Epoch 147/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6591 - acc: 0.5555 - val_loss: 0.7105 - val_acc: 0.5344\n",
      "Epoch 148/1000\n",
      "3784/3784 [==============================] - 1s 245us/step - loss: 0.6608 - acc: 0.5560 - val_loss: 0.7098 - val_acc: 0.5273\n",
      "Epoch 149/1000\n",
      "3784/3784 [==============================] - 1s 239us/step - loss: 0.6575 - acc: 0.5587 - val_loss: 0.7166 - val_acc: 0.5368\n",
      "Epoch 150/1000\n",
      "3784/3784 [==============================] - 1s 253us/step - loss: 0.6611 - acc: 0.5634 - val_loss: 0.7123 - val_acc: 0.5439\n",
      "Epoch 151/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6560 - acc: 0.5634 - val_loss: 0.7181 - val_acc: 0.5297\n",
      "Epoch 152/1000\n",
      "3784/3784 [==============================] - 1s 242us/step - loss: 0.6547 - acc: 0.5729 - val_loss: 0.7222 - val_acc: 0.5226\n",
      "Epoch 153/1000\n",
      "3784/3784 [==============================] - 1s 245us/step - loss: 0.6594 - acc: 0.5663 - val_loss: 0.7189 - val_acc: 0.5249\n",
      "Epoch 154/1000\n",
      "3784/3784 [==============================] - 1s 238us/step - loss: 0.6509 - acc: 0.5714 - val_loss: 0.7188 - val_acc: 0.5178\n",
      "Epoch 155/1000\n",
      "3784/3784 [==============================] - 1s 237us/step - loss: 0.6560 - acc: 0.5573 - val_loss: 0.7180 - val_acc: 0.5154\n",
      "Epoch 156/1000\n",
      "3784/3784 [==============================] - 1s 246us/step - loss: 0.6535 - acc: 0.5684 - val_loss: 0.7179 - val_acc: 0.5273\n",
      "Epoch 157/1000\n",
      "3784/3784 [==============================] - 1s 237us/step - loss: 0.6571 - acc: 0.5626 - val_loss: 0.7165 - val_acc: 0.5226\n",
      "Epoch 158/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.6545 - acc: 0.5671 - val_loss: 0.7181 - val_acc: 0.5344\n",
      "Epoch 159/1000\n",
      "3784/3784 [==============================] - 1s 237us/step - loss: 0.6574 - acc: 0.5692 - val_loss: 0.7219 - val_acc: 0.5321\n",
      "Epoch 160/1000\n",
      "3784/3784 [==============================] - 1s 251us/step - loss: 0.6572 - acc: 0.5716 - val_loss: 0.7158 - val_acc: 0.5202\n",
      "Epoch 161/1000\n",
      "3784/3784 [==============================] - 1s 250us/step - loss: 0.6559 - acc: 0.5719 - val_loss: 0.7145 - val_acc: 0.5249\n",
      "Epoch 162/1000\n",
      "3784/3784 [==============================] - 1s 248us/step - loss: 0.6547 - acc: 0.5597 - val_loss: 0.7149 - val_acc: 0.5202\n",
      "Epoch 163/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.6531 - acc: 0.5719 - val_loss: 0.7162 - val_acc: 0.5416\n",
      "Epoch 164/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6527 - acc: 0.5748 - val_loss: 0.7158 - val_acc: 0.5249\n",
      "Epoch 165/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6536 - acc: 0.5714 - val_loss: 0.7183 - val_acc: 0.5273\n",
      "Epoch 166/1000\n",
      "3784/3784 [==============================] - 1s 242us/step - loss: 0.6517 - acc: 0.5806 - val_loss: 0.7249 - val_acc: 0.5273\n",
      "Epoch 167/1000\n",
      "3784/3784 [==============================] - 1s 239us/step - loss: 0.6420 - acc: 0.5769 - val_loss: 0.7263 - val_acc: 0.5249\n",
      "Epoch 168/1000\n",
      "3784/3784 [==============================] - 1s 246us/step - loss: 0.6446 - acc: 0.5793 - val_loss: 0.7280 - val_acc: 0.5321\n",
      "Epoch 169/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6481 - acc: 0.5772 - val_loss: 0.7217 - val_acc: 0.5297\n",
      "Epoch 170/1000\n",
      "3784/3784 [==============================] - 1s 245us/step - loss: 0.6472 - acc: 0.5692 - val_loss: 0.7250 - val_acc: 0.5344\n",
      "Epoch 171/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.6523 - acc: 0.5737 - val_loss: 0.7234 - val_acc: 0.5273\n",
      "Epoch 172/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6485 - acc: 0.5666 - val_loss: 0.7264 - val_acc: 0.5202\n",
      "Epoch 173/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6449 - acc: 0.5803 - val_loss: 0.7413 - val_acc: 0.5083\n",
      "Epoch 174/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6442 - acc: 0.5729 - val_loss: 0.7282 - val_acc: 0.5226\n",
      "Epoch 175/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6476 - acc: 0.5745 - val_loss: 0.7224 - val_acc: 0.5273\n",
      "Epoch 176/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6435 - acc: 0.5846 - val_loss: 0.7257 - val_acc: 0.5416\n",
      "Epoch 177/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6496 - acc: 0.5748 - val_loss: 0.7232 - val_acc: 0.5321\n",
      "Epoch 178/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6465 - acc: 0.5785 - val_loss: 0.7275 - val_acc: 0.5202\n",
      "Epoch 179/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6464 - acc: 0.5751 - val_loss: 0.7295 - val_acc: 0.5297\n",
      "Epoch 180/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6488 - acc: 0.5737 - val_loss: 0.7296 - val_acc: 0.5154\n",
      "Epoch 181/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.6447 - acc: 0.5827 - val_loss: 0.7281 - val_acc: 0.5178\n",
      "Epoch 182/1000\n",
      "3784/3784 [==============================] - 1s 241us/step - loss: 0.6442 - acc: 0.5835 - val_loss: 0.7310 - val_acc: 0.5154\n",
      "Epoch 183/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.6377 - acc: 0.5811 - val_loss: 0.7246 - val_acc: 0.5368\n",
      "Epoch 184/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.6435 - acc: 0.5859 - val_loss: 0.7323 - val_acc: 0.5344\n",
      "Epoch 185/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.6440 - acc: 0.5790 - val_loss: 0.7285 - val_acc: 0.5344\n",
      "Epoch 186/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.6428 - acc: 0.5827 - val_loss: 0.7314 - val_acc: 0.5344\n",
      "Epoch 187/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6380 - acc: 0.5830 - val_loss: 0.7318 - val_acc: 0.5249\n",
      "Epoch 188/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.6374 - acc: 0.5835 - val_loss: 0.7423 - val_acc: 0.5249\n",
      "Epoch 189/1000\n",
      "3784/3784 [==============================] - 1s 238us/step - loss: 0.6386 - acc: 0.5893 - val_loss: 0.7359 - val_acc: 0.5249\n",
      "Epoch 190/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6419 - acc: 0.5809 - val_loss: 0.7382 - val_acc: 0.5202\n",
      "Epoch 191/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6361 - acc: 0.5825 - val_loss: 0.7382 - val_acc: 0.5154\n",
      "Epoch 192/1000\n",
      "3784/3784 [==============================] - 1s 247us/step - loss: 0.6395 - acc: 0.5811 - val_loss: 0.7407 - val_acc: 0.5012\n",
      "Epoch 193/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.6379 - acc: 0.5811 - val_loss: 0.7471 - val_acc: 0.5083\n",
      "Epoch 194/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6405 - acc: 0.5785 - val_loss: 0.7402 - val_acc: 0.5154\n",
      "Epoch 195/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.6436 - acc: 0.5904 - val_loss: 0.7377 - val_acc: 0.4988\n",
      "Epoch 196/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6394 - acc: 0.5848 - val_loss: 0.7364 - val_acc: 0.5107\n",
      "Epoch 197/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6345 - acc: 0.5830 - val_loss: 0.7383 - val_acc: 0.5059\n",
      "Epoch 198/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.6361 - acc: 0.5843 - val_loss: 0.7409 - val_acc: 0.5178\n",
      "Epoch 199/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.6335 - acc: 0.5801 - val_loss: 0.7418 - val_acc: 0.5154\n",
      "Epoch 200/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6314 - acc: 0.5893 - val_loss: 0.7485 - val_acc: 0.5012\n",
      "Epoch 201/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6287 - acc: 0.5930 - val_loss: 0.7444 - val_acc: 0.5154\n",
      "Epoch 202/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6328 - acc: 0.5880 - val_loss: 0.7466 - val_acc: 0.5249\n",
      "Epoch 203/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6402 - acc: 0.5843 - val_loss: 0.7436 - val_acc: 0.5083\n",
      "Epoch 204/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6399 - acc: 0.5777 - val_loss: 0.7437 - val_acc: 0.5202\n",
      "Epoch 205/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6226 - acc: 0.5986 - val_loss: 0.7496 - val_acc: 0.5202\n",
      "Epoch 206/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6281 - acc: 0.5938 - val_loss: 0.7533 - val_acc: 0.5178\n",
      "Epoch 207/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6399 - acc: 0.5848 - val_loss: 0.7424 - val_acc: 0.5321\n",
      "Epoch 208/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6350 - acc: 0.5872 - val_loss: 0.7483 - val_acc: 0.5107\n",
      "Epoch 209/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6345 - acc: 0.5851 - val_loss: 0.7378 - val_acc: 0.5131\n",
      "Epoch 210/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6326 - acc: 0.5838 - val_loss: 0.7430 - val_acc: 0.5226\n",
      "Epoch 211/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6283 - acc: 0.5917 - val_loss: 0.7556 - val_acc: 0.5202\n",
      "Epoch 212/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6306 - acc: 0.5928 - val_loss: 0.7543 - val_acc: 0.5036\n",
      "Epoch 213/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.6252 - acc: 0.5893 - val_loss: 0.7580 - val_acc: 0.5178\n",
      "Epoch 214/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6271 - acc: 0.5943 - val_loss: 0.7531 - val_acc: 0.5273\n",
      "Epoch 215/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6258 - acc: 0.5880 - val_loss: 0.7521 - val_acc: 0.5249\n",
      "Epoch 216/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.6245 - acc: 0.5959 - val_loss: 0.7536 - val_acc: 0.5131\n",
      "Epoch 217/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6260 - acc: 0.5851 - val_loss: 0.7571 - val_acc: 0.5012\n",
      "Epoch 218/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6205 - acc: 0.6023 - val_loss: 0.7600 - val_acc: 0.5059\n",
      "Epoch 219/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6243 - acc: 0.5875 - val_loss: 0.7641 - val_acc: 0.4964\n",
      "Epoch 220/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6240 - acc: 0.5967 - val_loss: 0.7669 - val_acc: 0.4964\n",
      "Epoch 221/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.6276 - acc: 0.5938 - val_loss: 0.7589 - val_acc: 0.4917\n",
      "Epoch 222/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6286 - acc: 0.5941 - val_loss: 0.7668 - val_acc: 0.5226\n",
      "Epoch 223/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.6228 - acc: 0.6060 - val_loss: 0.7722 - val_acc: 0.5226\n",
      "Epoch 224/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6249 - acc: 0.5994 - val_loss: 0.7628 - val_acc: 0.5249\n",
      "Epoch 225/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6301 - acc: 0.5906 - val_loss: 0.7638 - val_acc: 0.5321\n",
      "Epoch 226/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.6299 - acc: 0.5928 - val_loss: 0.7653 - val_acc: 0.5321\n",
      "Epoch 227/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6227 - acc: 0.5957 - val_loss: 0.7669 - val_acc: 0.5249\n",
      "Epoch 228/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6192 - acc: 0.5999 - val_loss: 0.7665 - val_acc: 0.5297\n",
      "Epoch 229/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.6222 - acc: 0.5962 - val_loss: 0.7642 - val_acc: 0.5249\n",
      "Epoch 230/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6216 - acc: 0.5941 - val_loss: 0.7613 - val_acc: 0.5249\n",
      "Epoch 231/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6203 - acc: 0.6002 - val_loss: 0.7657 - val_acc: 0.5178\n",
      "Epoch 232/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6193 - acc: 0.5983 - val_loss: 0.7802 - val_acc: 0.5321\n",
      "Epoch 233/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.6163 - acc: 0.6099 - val_loss: 0.7752 - val_acc: 0.5178\n",
      "Epoch 234/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6237 - acc: 0.5933 - val_loss: 0.7779 - val_acc: 0.5249\n",
      "Epoch 235/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6261 - acc: 0.5973 - val_loss: 0.7703 - val_acc: 0.5273\n",
      "Epoch 236/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.6216 - acc: 0.5965 - val_loss: 0.7796 - val_acc: 0.5012\n",
      "Epoch 237/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6148 - acc: 0.6033 - val_loss: 0.7788 - val_acc: 0.5273\n",
      "Epoch 238/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.6226 - acc: 0.5928 - val_loss: 0.7683 - val_acc: 0.5297\n",
      "Epoch 239/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.6184 - acc: 0.6012 - val_loss: 0.7668 - val_acc: 0.5297\n",
      "Epoch 240/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6162 - acc: 0.6081 - val_loss: 0.7754 - val_acc: 0.5321\n",
      "Epoch 241/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.6251 - acc: 0.5978 - val_loss: 0.7617 - val_acc: 0.5273\n",
      "Epoch 242/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6138 - acc: 0.6031 - val_loss: 0.7694 - val_acc: 0.5226\n",
      "Epoch 243/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.6208 - acc: 0.5994 - val_loss: 0.7673 - val_acc: 0.5202\n",
      "Epoch 244/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.6221 - acc: 0.6039 - val_loss: 0.7775 - val_acc: 0.5202\n",
      "Epoch 245/1000\n",
      "3784/3784 [==============================] - 1s 237us/step - loss: 0.6223 - acc: 0.5965 - val_loss: 0.7769 - val_acc: 0.5297\n",
      "Epoch 246/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.6175 - acc: 0.6025 - val_loss: 0.7764 - val_acc: 0.5131\n",
      "Epoch 247/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.6147 - acc: 0.6015 - val_loss: 0.7819 - val_acc: 0.5202\n",
      "Epoch 248/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6170 - acc: 0.5978 - val_loss: 0.7791 - val_acc: 0.5202\n",
      "Epoch 249/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6199 - acc: 0.5973 - val_loss: 0.7798 - val_acc: 0.5273\n",
      "Epoch 250/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6092 - acc: 0.6176 - val_loss: 0.7751 - val_acc: 0.5178\n",
      "Epoch 251/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6181 - acc: 0.6054 - val_loss: 0.7687 - val_acc: 0.5273\n",
      "Epoch 252/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6101 - acc: 0.6102 - val_loss: 0.7807 - val_acc: 0.5249\n",
      "Epoch 253/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6162 - acc: 0.5986 - val_loss: 0.7750 - val_acc: 0.5131\n",
      "Epoch 254/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.6115 - acc: 0.6089 - val_loss: 0.7743 - val_acc: 0.5202\n",
      "Epoch 255/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6145 - acc: 0.6036 - val_loss: 0.7743 - val_acc: 0.5202\n",
      "Epoch 256/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6066 - acc: 0.6150 - val_loss: 0.7814 - val_acc: 0.5202\n",
      "Epoch 257/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6094 - acc: 0.6136 - val_loss: 0.7849 - val_acc: 0.5273\n",
      "Epoch 258/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6134 - acc: 0.6028 - val_loss: 0.7727 - val_acc: 0.5154\n",
      "Epoch 259/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6130 - acc: 0.6002 - val_loss: 0.7792 - val_acc: 0.5154\n",
      "Epoch 260/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.6100 - acc: 0.5986 - val_loss: 0.7855 - val_acc: 0.5202\n",
      "Epoch 261/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6074 - acc: 0.6134 - val_loss: 0.7955 - val_acc: 0.5344\n",
      "Epoch 262/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6147 - acc: 0.6020 - val_loss: 0.7876 - val_acc: 0.5368\n",
      "Epoch 263/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6062 - acc: 0.6060 - val_loss: 0.7935 - val_acc: 0.5297\n",
      "Epoch 264/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6112 - acc: 0.6070 - val_loss: 0.7839 - val_acc: 0.5321\n",
      "Epoch 265/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6135 - acc: 0.6049 - val_loss: 0.7835 - val_acc: 0.5083\n",
      "Epoch 266/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6088 - acc: 0.6163 - val_loss: 0.7860 - val_acc: 0.5202\n",
      "Epoch 267/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6034 - acc: 0.6160 - val_loss: 0.8039 - val_acc: 0.5273\n",
      "Epoch 268/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.6094 - acc: 0.6054 - val_loss: 0.7946 - val_acc: 0.5226\n",
      "Epoch 269/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.6066 - acc: 0.6107 - val_loss: 0.7937 - val_acc: 0.5321\n",
      "Epoch 270/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.6090 - acc: 0.6187 - val_loss: 0.7927 - val_acc: 0.5297\n",
      "Epoch 271/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6093 - acc: 0.6165 - val_loss: 0.8028 - val_acc: 0.5202\n",
      "Epoch 272/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.6075 - acc: 0.6028 - val_loss: 0.8016 - val_acc: 0.5344\n",
      "Epoch 273/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6054 - acc: 0.6147 - val_loss: 0.7979 - val_acc: 0.5273\n",
      "Epoch 274/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6135 - acc: 0.6039 - val_loss: 0.7898 - val_acc: 0.5416\n",
      "Epoch 275/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.6004 - acc: 0.6113 - val_loss: 0.8025 - val_acc: 0.5344\n",
      "Epoch 276/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6049 - acc: 0.6110 - val_loss: 0.7982 - val_acc: 0.5273\n",
      "Epoch 277/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.5956 - acc: 0.6195 - val_loss: 0.8018 - val_acc: 0.5297\n",
      "Epoch 278/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6066 - acc: 0.6158 - val_loss: 0.8106 - val_acc: 0.5463\n",
      "Epoch 279/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5991 - acc: 0.6128 - val_loss: 0.7993 - val_acc: 0.5463\n",
      "Epoch 280/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6052 - acc: 0.6068 - val_loss: 0.7954 - val_acc: 0.5416\n",
      "Epoch 281/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6018 - acc: 0.6089 - val_loss: 0.8029 - val_acc: 0.5416\n",
      "Epoch 282/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6040 - acc: 0.6094 - val_loss: 0.7912 - val_acc: 0.5273\n",
      "Epoch 283/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5930 - acc: 0.6189 - val_loss: 0.8046 - val_acc: 0.5226\n",
      "Epoch 284/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5989 - acc: 0.6144 - val_loss: 0.8094 - val_acc: 0.5249\n",
      "Epoch 285/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6050 - acc: 0.6107 - val_loss: 0.8001 - val_acc: 0.5297\n",
      "Epoch 286/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.5985 - acc: 0.6155 - val_loss: 0.7957 - val_acc: 0.5297\n",
      "Epoch 287/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6014 - acc: 0.6123 - val_loss: 0.8033 - val_acc: 0.5344\n",
      "Epoch 288/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6007 - acc: 0.6123 - val_loss: 0.8058 - val_acc: 0.5416\n",
      "Epoch 289/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5965 - acc: 0.6192 - val_loss: 0.8027 - val_acc: 0.5416\n",
      "Epoch 290/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.6068 - acc: 0.6070 - val_loss: 0.7942 - val_acc: 0.5202\n",
      "Epoch 291/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.6006 - acc: 0.6147 - val_loss: 0.7947 - val_acc: 0.5107\n",
      "Epoch 292/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5962 - acc: 0.6152 - val_loss: 0.7993 - val_acc: 0.5202\n",
      "Epoch 293/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.6030 - acc: 0.6197 - val_loss: 0.7951 - val_acc: 0.5178\n",
      "Epoch 294/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5964 - acc: 0.6181 - val_loss: 0.7959 - val_acc: 0.5321\n",
      "Epoch 295/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.5963 - acc: 0.6202 - val_loss: 0.8021 - val_acc: 0.5273\n",
      "Epoch 296/1000\n",
      "3784/3784 [==============================] - 1s 242us/step - loss: 0.5964 - acc: 0.6210 - val_loss: 0.8090 - val_acc: 0.5297\n",
      "Epoch 297/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.5983 - acc: 0.6155 - val_loss: 0.7909 - val_acc: 0.5249\n",
      "Epoch 298/1000\n",
      "3784/3784 [==============================] - 1s 242us/step - loss: 0.6001 - acc: 0.6245 - val_loss: 0.7883 - val_acc: 0.5344\n",
      "Epoch 299/1000\n",
      "3784/3784 [==============================] - 1s 247us/step - loss: 0.5942 - acc: 0.6173 - val_loss: 0.7989 - val_acc: 0.5392\n",
      "Epoch 300/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.6047 - acc: 0.6155 - val_loss: 0.7886 - val_acc: 0.5297\n",
      "Epoch 301/1000\n",
      "3784/3784 [==============================] - 1s 251us/step - loss: 0.6012 - acc: 0.6126 - val_loss: 0.7921 - val_acc: 0.5297\n",
      "Epoch 302/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.6032 - acc: 0.6134 - val_loss: 0.8044 - val_acc: 0.5344\n",
      "Epoch 303/1000\n",
      "3784/3784 [==============================] - 1s 258us/step - loss: 0.5946 - acc: 0.6229 - val_loss: 0.8000 - val_acc: 0.5392\n",
      "Epoch 304/1000\n",
      "3784/3784 [==============================] - 1s 248us/step - loss: 0.6128 - acc: 0.6068 - val_loss: 0.7886 - val_acc: 0.5154\n",
      "Epoch 305/1000\n",
      "3784/3784 [==============================] - 1s 240us/step - loss: 0.5930 - acc: 0.6192 - val_loss: 0.7991 - val_acc: 0.5083\n",
      "Epoch 306/1000\n",
      "3784/3784 [==============================] - 1s 246us/step - loss: 0.5933 - acc: 0.6184 - val_loss: 0.8023 - val_acc: 0.5368\n",
      "Epoch 307/1000\n",
      "3784/3784 [==============================] - 1s 256us/step - loss: 0.5959 - acc: 0.6123 - val_loss: 0.8042 - val_acc: 0.5226\n",
      "Epoch 308/1000\n",
      "3784/3784 [==============================] - 1s 246us/step - loss: 0.5907 - acc: 0.6216 - val_loss: 0.8119 - val_acc: 0.5273\n",
      "Epoch 309/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.5967 - acc: 0.6176 - val_loss: 0.8151 - val_acc: 0.5154\n",
      "Epoch 310/1000\n",
      "3784/3784 [==============================] - 1s 239us/step - loss: 0.6001 - acc: 0.6158 - val_loss: 0.8121 - val_acc: 0.5178\n",
      "Epoch 311/1000\n",
      "3784/3784 [==============================] - 1s 252us/step - loss: 0.5902 - acc: 0.6192 - val_loss: 0.8182 - val_acc: 0.5154\n",
      "Epoch 312/1000\n",
      "3784/3784 [==============================] - 1s 253us/step - loss: 0.5981 - acc: 0.6097 - val_loss: 0.8072 - val_acc: 0.5202\n",
      "Epoch 313/1000\n",
      "3784/3784 [==============================] - 1s 244us/step - loss: 0.5920 - acc: 0.6213 - val_loss: 0.8098 - val_acc: 0.5321\n",
      "Epoch 314/1000\n",
      "3784/3784 [==============================] - 1s 245us/step - loss: 0.5886 - acc: 0.6263 - val_loss: 0.8198 - val_acc: 0.5463\n",
      "Epoch 315/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.5938 - acc: 0.6197 - val_loss: 0.8142 - val_acc: 0.5392\n",
      "Epoch 316/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.5901 - acc: 0.6213 - val_loss: 0.8119 - val_acc: 0.5344\n",
      "Epoch 317/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.5906 - acc: 0.6242 - val_loss: 0.8222 - val_acc: 0.5392\n",
      "Epoch 318/1000\n",
      "3784/3784 [==============================] - 1s 241us/step - loss: 0.5852 - acc: 0.6250 - val_loss: 0.8244 - val_acc: 0.5416\n",
      "Epoch 319/1000\n",
      "3784/3784 [==============================] - 1s 243us/step - loss: 0.5884 - acc: 0.6276 - val_loss: 0.8193 - val_acc: 0.5439\n",
      "Epoch 320/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.5882 - acc: 0.6176 - val_loss: 0.8248 - val_acc: 0.5297\n",
      "Epoch 321/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.5896 - acc: 0.6189 - val_loss: 0.8151 - val_acc: 0.5344\n",
      "Epoch 322/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.5913 - acc: 0.6152 - val_loss: 0.8143 - val_acc: 0.5273\n",
      "Epoch 323/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.5888 - acc: 0.6165 - val_loss: 0.8104 - val_acc: 0.5154\n",
      "Epoch 324/1000\n",
      "3784/3784 [==============================] - 1s 243us/step - loss: 0.5893 - acc: 0.6292 - val_loss: 0.8238 - val_acc: 0.5226\n",
      "Epoch 325/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.5853 - acc: 0.6329 - val_loss: 0.8293 - val_acc: 0.5344\n",
      "Epoch 326/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.5943 - acc: 0.6189 - val_loss: 0.8181 - val_acc: 0.5321\n",
      "Epoch 327/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.5915 - acc: 0.6192 - val_loss: 0.8201 - val_acc: 0.5416\n",
      "Epoch 328/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.5961 - acc: 0.6165 - val_loss: 0.8246 - val_acc: 0.5249\n",
      "Epoch 329/1000\n",
      "3784/3784 [==============================] - 1s 242us/step - loss: 0.5881 - acc: 0.6245 - val_loss: 0.8266 - val_acc: 0.5344\n",
      "Epoch 330/1000\n",
      "3784/3784 [==============================] - 1s 247us/step - loss: 0.5913 - acc: 0.6126 - val_loss: 0.8230 - val_acc: 0.5368\n",
      "Epoch 331/1000\n",
      "3784/3784 [==============================] - 1s 250us/step - loss: 0.5877 - acc: 0.6221 - val_loss: 0.8193 - val_acc: 0.5273\n",
      "Epoch 332/1000\n",
      "3784/3784 [==============================] - 1s 253us/step - loss: 0.5883 - acc: 0.6171 - val_loss: 0.8158 - val_acc: 0.5344\n",
      "Epoch 333/1000\n",
      "3784/3784 [==============================] - 1s 245us/step - loss: 0.5893 - acc: 0.6197 - val_loss: 0.8245 - val_acc: 0.5321\n",
      "Epoch 334/1000\n",
      "3784/3784 [==============================] - 1s 253us/step - loss: 0.5866 - acc: 0.6263 - val_loss: 0.8279 - val_acc: 0.5321\n",
      "Epoch 335/1000\n",
      "3784/3784 [==============================] - 1s 241us/step - loss: 0.5859 - acc: 0.6295 - val_loss: 0.8224 - val_acc: 0.5226\n",
      "Epoch 336/1000\n",
      "3784/3784 [==============================] - 1s 256us/step - loss: 0.5806 - acc: 0.6308 - val_loss: 0.8238 - val_acc: 0.5154\n",
      "Epoch 337/1000\n",
      "3784/3784 [==============================] - 1s 241us/step - loss: 0.5817 - acc: 0.6263 - val_loss: 0.8346 - val_acc: 0.5178\n",
      "Epoch 338/1000\n",
      "3784/3784 [==============================] - 1s 240us/step - loss: 0.5868 - acc: 0.6208 - val_loss: 0.8281 - val_acc: 0.5178\n",
      "Epoch 339/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.5853 - acc: 0.6171 - val_loss: 0.8309 - val_acc: 0.5202\n",
      "Epoch 340/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5852 - acc: 0.6258 - val_loss: 0.8416 - val_acc: 0.5036\n",
      "Epoch 341/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5823 - acc: 0.6282 - val_loss: 0.8350 - val_acc: 0.5178\n",
      "Epoch 342/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5811 - acc: 0.6300 - val_loss: 0.8327 - val_acc: 0.5273\n",
      "Epoch 343/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5811 - acc: 0.6287 - val_loss: 0.8377 - val_acc: 0.5202\n",
      "Epoch 344/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5842 - acc: 0.6335 - val_loss: 0.8387 - val_acc: 0.5178\n",
      "Epoch 345/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5808 - acc: 0.6295 - val_loss: 0.8286 - val_acc: 0.5202\n",
      "Epoch 346/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5797 - acc: 0.6337 - val_loss: 0.8436 - val_acc: 0.5226\n",
      "Epoch 347/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5888 - acc: 0.6229 - val_loss: 0.8229 - val_acc: 0.5131\n",
      "Epoch 348/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5871 - acc: 0.6253 - val_loss: 0.8281 - val_acc: 0.5202\n",
      "Epoch 349/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.5807 - acc: 0.6271 - val_loss: 0.8263 - val_acc: 0.5249\n",
      "Epoch 350/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5870 - acc: 0.6218 - val_loss: 0.8267 - val_acc: 0.5273\n",
      "Epoch 351/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5825 - acc: 0.6239 - val_loss: 0.8263 - val_acc: 0.5249\n",
      "Epoch 352/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.5785 - acc: 0.6258 - val_loss: 0.8290 - val_acc: 0.5178\n",
      "Epoch 353/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5749 - acc: 0.6369 - val_loss: 0.8382 - val_acc: 0.5273\n",
      "Epoch 354/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5733 - acc: 0.6374 - val_loss: 0.8281 - val_acc: 0.5321\n",
      "Epoch 355/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5770 - acc: 0.6356 - val_loss: 0.8490 - val_acc: 0.5178\n",
      "Epoch 356/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5760 - acc: 0.6284 - val_loss: 0.8351 - val_acc: 0.5226\n",
      "Epoch 357/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5834 - acc: 0.6284 - val_loss: 0.8389 - val_acc: 0.5178\n",
      "Epoch 358/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5747 - acc: 0.6379 - val_loss: 0.8396 - val_acc: 0.5178\n",
      "Epoch 359/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5834 - acc: 0.6239 - val_loss: 0.8328 - val_acc: 0.5249\n",
      "Epoch 360/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5742 - acc: 0.6290 - val_loss: 0.8359 - val_acc: 0.5202\n",
      "Epoch 361/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5858 - acc: 0.6208 - val_loss: 0.8340 - val_acc: 0.5392\n",
      "Epoch 362/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5728 - acc: 0.6340 - val_loss: 0.8367 - val_acc: 0.5368\n",
      "Epoch 363/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5768 - acc: 0.6382 - val_loss: 0.8440 - val_acc: 0.5344\n",
      "Epoch 364/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5773 - acc: 0.6313 - val_loss: 0.8239 - val_acc: 0.5368\n",
      "Epoch 365/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5715 - acc: 0.6353 - val_loss: 0.8425 - val_acc: 0.5392\n",
      "Epoch 366/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5684 - acc: 0.6364 - val_loss: 0.8599 - val_acc: 0.5297\n",
      "Epoch 367/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5739 - acc: 0.6319 - val_loss: 0.8580 - val_acc: 0.5297\n",
      "Epoch 368/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5831 - acc: 0.6247 - val_loss: 0.8477 - val_acc: 0.5321\n",
      "Epoch 369/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5699 - acc: 0.6313 - val_loss: 0.8487 - val_acc: 0.5392\n",
      "Epoch 370/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5701 - acc: 0.6379 - val_loss: 0.8517 - val_acc: 0.5368\n",
      "Epoch 371/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5746 - acc: 0.6250 - val_loss: 0.8510 - val_acc: 0.5368\n",
      "Epoch 372/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5732 - acc: 0.6327 - val_loss: 0.8536 - val_acc: 0.5344\n",
      "Epoch 373/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5804 - acc: 0.6237 - val_loss: 0.8395 - val_acc: 0.5439\n",
      "Epoch 374/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5736 - acc: 0.6337 - val_loss: 0.8395 - val_acc: 0.5487\n",
      "Epoch 375/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5750 - acc: 0.6300 - val_loss: 0.8284 - val_acc: 0.5249\n",
      "Epoch 376/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.5753 - acc: 0.6321 - val_loss: 0.8454 - val_acc: 0.5392\n",
      "Epoch 377/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.5700 - acc: 0.6308 - val_loss: 0.8404 - val_acc: 0.5368\n",
      "Epoch 378/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5770 - acc: 0.6274 - val_loss: 0.8484 - val_acc: 0.5344\n",
      "Epoch 379/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.5703 - acc: 0.6321 - val_loss: 0.8507 - val_acc: 0.5321\n",
      "Epoch 380/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.5750 - acc: 0.6300 - val_loss: 0.8437 - val_acc: 0.5344\n",
      "Epoch 381/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5707 - acc: 0.6300 - val_loss: 0.8423 - val_acc: 0.5297\n",
      "Epoch 382/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5704 - acc: 0.6345 - val_loss: 0.8318 - val_acc: 0.5273\n",
      "Epoch 383/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5745 - acc: 0.6327 - val_loss: 0.8399 - val_acc: 0.5226\n",
      "Epoch 384/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5749 - acc: 0.6403 - val_loss: 0.8563 - val_acc: 0.5273\n",
      "Epoch 385/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5679 - acc: 0.6427 - val_loss: 0.8513 - val_acc: 0.5297\n",
      "Epoch 386/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5624 - acc: 0.6422 - val_loss: 0.8524 - val_acc: 0.5344\n",
      "Epoch 387/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5726 - acc: 0.6313 - val_loss: 0.8437 - val_acc: 0.5273\n",
      "Epoch 388/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5675 - acc: 0.6340 - val_loss: 0.8494 - val_acc: 0.5273\n",
      "Epoch 389/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5679 - acc: 0.6356 - val_loss: 0.8730 - val_acc: 0.5297\n",
      "Epoch 390/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5653 - acc: 0.6366 - val_loss: 0.8554 - val_acc: 0.5178\n",
      "Epoch 391/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5703 - acc: 0.6422 - val_loss: 0.8468 - val_acc: 0.5297\n",
      "Epoch 392/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5679 - acc: 0.6485 - val_loss: 0.8693 - val_acc: 0.5511\n",
      "Epoch 393/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5671 - acc: 0.6274 - val_loss: 0.8674 - val_acc: 0.5463\n",
      "Epoch 394/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5664 - acc: 0.6366 - val_loss: 0.8635 - val_acc: 0.5297\n",
      "Epoch 395/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5639 - acc: 0.6361 - val_loss: 0.8799 - val_acc: 0.5416\n",
      "Epoch 396/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5625 - acc: 0.6448 - val_loss: 0.8737 - val_acc: 0.5392\n",
      "Epoch 397/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5698 - acc: 0.6364 - val_loss: 0.8632 - val_acc: 0.5344\n",
      "Epoch 398/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5663 - acc: 0.6345 - val_loss: 0.8515 - val_acc: 0.5344\n",
      "Epoch 399/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5645 - acc: 0.6430 - val_loss: 0.8504 - val_acc: 0.5416\n",
      "Epoch 400/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5632 - acc: 0.6422 - val_loss: 0.8639 - val_acc: 0.5297\n",
      "Epoch 401/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5679 - acc: 0.6353 - val_loss: 0.8509 - val_acc: 0.5416\n",
      "Epoch 402/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5730 - acc: 0.6324 - val_loss: 0.8560 - val_acc: 0.5487\n",
      "Epoch 403/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.5612 - acc: 0.6456 - val_loss: 0.8707 - val_acc: 0.5463\n",
      "Epoch 404/1000\n",
      "3784/3784 [==============================] - 1s 223us/step - loss: 0.5598 - acc: 0.6430 - val_loss: 0.8636 - val_acc: 0.5321\n",
      "Epoch 405/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5665 - acc: 0.6329 - val_loss: 0.8670 - val_acc: 0.5321\n",
      "Epoch 406/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.5616 - acc: 0.6401 - val_loss: 0.8650 - val_acc: 0.5226\n",
      "Epoch 407/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5652 - acc: 0.6321 - val_loss: 0.8706 - val_acc: 0.5321\n",
      "Epoch 408/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5601 - acc: 0.6398 - val_loss: 0.8716 - val_acc: 0.5273\n",
      "Epoch 409/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5633 - acc: 0.6411 - val_loss: 0.8682 - val_acc: 0.5368\n",
      "Epoch 410/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5671 - acc: 0.6350 - val_loss: 0.8770 - val_acc: 0.5178\n",
      "Epoch 411/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5684 - acc: 0.6403 - val_loss: 0.8650 - val_acc: 0.5416\n",
      "Epoch 412/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5613 - acc: 0.6477 - val_loss: 0.8655 - val_acc: 0.5511\n",
      "Epoch 413/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5565 - acc: 0.6419 - val_loss: 0.8622 - val_acc: 0.5487\n",
      "Epoch 414/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.5550 - acc: 0.6422 - val_loss: 0.8653 - val_acc: 0.5416\n",
      "Epoch 415/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5652 - acc: 0.6390 - val_loss: 0.8549 - val_acc: 0.5416\n",
      "Epoch 416/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5570 - acc: 0.6387 - val_loss: 0.8640 - val_acc: 0.5511\n",
      "Epoch 417/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5523 - acc: 0.6496 - val_loss: 0.8611 - val_acc: 0.5463\n",
      "Epoch 418/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5690 - acc: 0.6411 - val_loss: 0.8500 - val_acc: 0.5416\n",
      "Epoch 419/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5550 - acc: 0.6488 - val_loss: 0.8609 - val_acc: 0.5249\n",
      "Epoch 420/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5559 - acc: 0.6448 - val_loss: 0.8688 - val_acc: 0.5416\n",
      "Epoch 421/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5548 - acc: 0.6480 - val_loss: 0.8657 - val_acc: 0.5487\n",
      "Epoch 422/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5575 - acc: 0.6427 - val_loss: 0.8619 - val_acc: 0.5297\n",
      "Epoch 423/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5595 - acc: 0.6358 - val_loss: 0.8616 - val_acc: 0.5273\n",
      "Epoch 424/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5549 - acc: 0.6451 - val_loss: 0.8823 - val_acc: 0.5178\n",
      "Epoch 425/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5694 - acc: 0.6353 - val_loss: 0.8563 - val_acc: 0.5249\n",
      "Epoch 426/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5637 - acc: 0.6364 - val_loss: 0.8547 - val_acc: 0.5321\n",
      "Epoch 427/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5570 - acc: 0.6477 - val_loss: 0.8770 - val_acc: 0.5439\n",
      "Epoch 428/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5538 - acc: 0.6477 - val_loss: 0.8916 - val_acc: 0.5368\n",
      "Epoch 429/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5581 - acc: 0.6422 - val_loss: 0.8684 - val_acc: 0.5249\n",
      "Epoch 430/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.5591 - acc: 0.6422 - val_loss: 0.8676 - val_acc: 0.5273\n",
      "Epoch 431/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5605 - acc: 0.6451 - val_loss: 0.8770 - val_acc: 0.5273\n",
      "Epoch 432/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5584 - acc: 0.6379 - val_loss: 0.8685 - val_acc: 0.5226\n",
      "Epoch 433/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5531 - acc: 0.6424 - val_loss: 0.8863 - val_acc: 0.5202\n",
      "Epoch 434/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5548 - acc: 0.6435 - val_loss: 0.8796 - val_acc: 0.5178\n",
      "Epoch 435/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5543 - acc: 0.6451 - val_loss: 0.8805 - val_acc: 0.5226\n",
      "Epoch 436/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5539 - acc: 0.6506 - val_loss: 0.8734 - val_acc: 0.5226\n",
      "Epoch 437/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5606 - acc: 0.6472 - val_loss: 0.8735 - val_acc: 0.5273\n",
      "Epoch 438/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5482 - acc: 0.6480 - val_loss: 0.8934 - val_acc: 0.5297\n",
      "Epoch 439/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5559 - acc: 0.6435 - val_loss: 0.8913 - val_acc: 0.5249\n",
      "Epoch 440/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5680 - acc: 0.6438 - val_loss: 0.8757 - val_acc: 0.5368\n",
      "Epoch 441/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5595 - acc: 0.6409 - val_loss: 0.8666 - val_acc: 0.5321\n",
      "Epoch 442/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5550 - acc: 0.6406 - val_loss: 0.8659 - val_acc: 0.5249\n",
      "Epoch 443/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5531 - acc: 0.6432 - val_loss: 0.8764 - val_acc: 0.5416\n",
      "Epoch 444/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5544 - acc: 0.6456 - val_loss: 0.8910 - val_acc: 0.5392\n",
      "Epoch 445/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5525 - acc: 0.6501 - val_loss: 0.8797 - val_acc: 0.5368\n",
      "Epoch 446/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5551 - acc: 0.6477 - val_loss: 0.8807 - val_acc: 0.5416\n",
      "Epoch 447/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5473 - acc: 0.6401 - val_loss: 0.8849 - val_acc: 0.5344\n",
      "Epoch 448/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5541 - acc: 0.6467 - val_loss: 0.8867 - val_acc: 0.5392\n",
      "Epoch 449/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5531 - acc: 0.6483 - val_loss: 0.8730 - val_acc: 0.5297\n",
      "Epoch 450/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5555 - acc: 0.6416 - val_loss: 0.8891 - val_acc: 0.5297\n",
      "Epoch 451/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5624 - acc: 0.6472 - val_loss: 0.8828 - val_acc: 0.5226\n",
      "Epoch 452/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5444 - acc: 0.6493 - val_loss: 0.8867 - val_acc: 0.5297\n",
      "Epoch 453/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5447 - acc: 0.6522 - val_loss: 0.8884 - val_acc: 0.5439\n",
      "Epoch 454/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5498 - acc: 0.6504 - val_loss: 0.9053 - val_acc: 0.5368\n",
      "Epoch 455/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5487 - acc: 0.6490 - val_loss: 0.9077 - val_acc: 0.5368\n",
      "Epoch 456/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5490 - acc: 0.6520 - val_loss: 0.8956 - val_acc: 0.5344\n",
      "Epoch 457/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.5477 - acc: 0.6493 - val_loss: 0.9022 - val_acc: 0.5439\n",
      "Epoch 458/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5465 - acc: 0.6469 - val_loss: 0.8851 - val_acc: 0.5416\n",
      "Epoch 459/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5454 - acc: 0.6522 - val_loss: 0.8912 - val_acc: 0.5392\n",
      "Epoch 460/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5547 - acc: 0.6451 - val_loss: 0.8945 - val_acc: 0.5344\n",
      "Epoch 461/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5522 - acc: 0.6496 - val_loss: 0.8915 - val_acc: 0.5463\n",
      "Epoch 462/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5533 - acc: 0.6480 - val_loss: 0.8967 - val_acc: 0.5344\n",
      "Epoch 463/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5486 - acc: 0.6496 - val_loss: 0.8913 - val_acc: 0.5344\n",
      "Epoch 464/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5467 - acc: 0.6490 - val_loss: 0.9046 - val_acc: 0.5297\n",
      "Epoch 465/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5439 - acc: 0.6538 - val_loss: 0.8876 - val_acc: 0.5344\n",
      "Epoch 466/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5444 - acc: 0.6567 - val_loss: 0.9071 - val_acc: 0.5321\n",
      "Epoch 467/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5453 - acc: 0.6501 - val_loss: 0.9223 - val_acc: 0.5273\n",
      "Epoch 468/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5394 - acc: 0.6517 - val_loss: 0.9045 - val_acc: 0.5344\n",
      "Epoch 469/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5398 - acc: 0.6564 - val_loss: 0.9006 - val_acc: 0.5297\n",
      "Epoch 470/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5423 - acc: 0.6498 - val_loss: 0.9008 - val_acc: 0.5273\n",
      "Epoch 471/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5427 - acc: 0.6501 - val_loss: 0.8819 - val_acc: 0.5273\n",
      "Epoch 472/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5496 - acc: 0.6469 - val_loss: 0.8943 - val_acc: 0.5273\n",
      "Epoch 473/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5454 - acc: 0.6483 - val_loss: 0.9014 - val_acc: 0.5273\n",
      "Epoch 474/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5417 - acc: 0.6498 - val_loss: 0.9029 - val_acc: 0.5202\n",
      "Epoch 475/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5501 - acc: 0.6469 - val_loss: 0.8931 - val_acc: 0.5273\n",
      "Epoch 476/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5524 - acc: 0.6504 - val_loss: 0.8976 - val_acc: 0.5178\n",
      "Epoch 477/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.5475 - acc: 0.6525 - val_loss: 0.8947 - val_acc: 0.5297\n",
      "Epoch 478/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5432 - acc: 0.6580 - val_loss: 0.8995 - val_acc: 0.5368\n",
      "Epoch 479/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5448 - acc: 0.6628 - val_loss: 0.9023 - val_acc: 0.5273\n",
      "Epoch 480/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5447 - acc: 0.6520 - val_loss: 0.9121 - val_acc: 0.5226\n",
      "Epoch 481/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5359 - acc: 0.6541 - val_loss: 0.9190 - val_acc: 0.5321\n",
      "Epoch 482/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5436 - acc: 0.6554 - val_loss: 0.9096 - val_acc: 0.5321\n",
      "Epoch 483/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5495 - acc: 0.6533 - val_loss: 0.9109 - val_acc: 0.5344\n",
      "Epoch 484/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.5425 - acc: 0.6493 - val_loss: 0.9145 - val_acc: 0.5297\n",
      "Epoch 485/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5451 - acc: 0.6586 - val_loss: 0.9187 - val_acc: 0.5392\n",
      "Epoch 486/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5496 - acc: 0.6467 - val_loss: 0.9385 - val_acc: 0.5416\n",
      "Epoch 487/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5430 - acc: 0.6570 - val_loss: 0.9152 - val_acc: 0.5439\n",
      "Epoch 488/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5406 - acc: 0.6541 - val_loss: 0.9281 - val_acc: 0.5249\n",
      "Epoch 489/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5430 - acc: 0.6517 - val_loss: 0.9228 - val_acc: 0.5439\n",
      "Epoch 490/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5360 - acc: 0.6525 - val_loss: 0.9310 - val_acc: 0.5321\n",
      "Epoch 491/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5469 - acc: 0.6533 - val_loss: 0.9157 - val_acc: 0.5344\n",
      "Epoch 492/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.5399 - acc: 0.6591 - val_loss: 0.9227 - val_acc: 0.5368\n",
      "Epoch 493/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5468 - acc: 0.6490 - val_loss: 0.9210 - val_acc: 0.5463\n",
      "Epoch 494/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5486 - acc: 0.6472 - val_loss: 0.9060 - val_acc: 0.5416\n",
      "Epoch 495/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5451 - acc: 0.6594 - val_loss: 0.9110 - val_acc: 0.5392\n",
      "Epoch 496/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.5353 - acc: 0.6557 - val_loss: 0.9182 - val_acc: 0.5297\n",
      "Epoch 497/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5553 - acc: 0.6467 - val_loss: 0.9015 - val_acc: 0.5344\n",
      "Epoch 498/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5364 - acc: 0.6527 - val_loss: 0.9177 - val_acc: 0.5368\n",
      "Epoch 499/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5426 - acc: 0.6504 - val_loss: 0.9088 - val_acc: 0.5439\n",
      "Epoch 500/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5396 - acc: 0.6580 - val_loss: 0.9037 - val_acc: 0.5439\n",
      "Epoch 501/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5331 - acc: 0.6583 - val_loss: 0.9276 - val_acc: 0.5368\n",
      "Epoch 502/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5458 - acc: 0.6546 - val_loss: 0.9192 - val_acc: 0.5392\n",
      "Epoch 503/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5484 - acc: 0.6504 - val_loss: 0.9015 - val_acc: 0.5392\n",
      "Epoch 504/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5470 - acc: 0.6562 - val_loss: 0.9209 - val_acc: 0.5534\n",
      "Epoch 505/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5354 - acc: 0.6609 - val_loss: 0.9241 - val_acc: 0.5582\n",
      "Epoch 506/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5404 - acc: 0.6509 - val_loss: 0.9230 - val_acc: 0.5606\n",
      "Epoch 507/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5321 - acc: 0.6596 - val_loss: 0.9233 - val_acc: 0.5534\n",
      "Epoch 508/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5394 - acc: 0.6493 - val_loss: 0.9107 - val_acc: 0.5558\n",
      "Epoch 509/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.5374 - acc: 0.6522 - val_loss: 0.9138 - val_acc: 0.5511\n",
      "Epoch 510/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5358 - acc: 0.6567 - val_loss: 0.9204 - val_acc: 0.5368\n",
      "Epoch 511/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.5383 - acc: 0.6541 - val_loss: 0.9228 - val_acc: 0.5416\n",
      "Epoch 512/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5350 - acc: 0.6506 - val_loss: 0.9154 - val_acc: 0.5321\n",
      "Epoch 513/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5271 - acc: 0.6736 - val_loss: 0.9310 - val_acc: 0.5416\n",
      "Epoch 514/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5367 - acc: 0.6533 - val_loss: 0.9340 - val_acc: 0.5368\n",
      "Epoch 515/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5423 - acc: 0.6541 - val_loss: 0.9047 - val_acc: 0.5392\n",
      "Epoch 516/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5384 - acc: 0.6488 - val_loss: 0.9177 - val_acc: 0.5249\n",
      "Epoch 517/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5371 - acc: 0.6580 - val_loss: 0.9214 - val_acc: 0.5416\n",
      "Epoch 518/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5224 - acc: 0.6652 - val_loss: 0.9386 - val_acc: 0.5392\n",
      "Epoch 519/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5316 - acc: 0.6533 - val_loss: 0.9343 - val_acc: 0.5368\n",
      "Epoch 520/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5419 - acc: 0.6533 - val_loss: 0.9344 - val_acc: 0.5392\n",
      "Epoch 521/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5357 - acc: 0.6498 - val_loss: 0.9486 - val_acc: 0.5297\n",
      "Epoch 522/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5314 - acc: 0.6596 - val_loss: 0.9418 - val_acc: 0.5368\n",
      "Epoch 523/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5332 - acc: 0.6546 - val_loss: 0.9466 - val_acc: 0.5321\n",
      "Epoch 524/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5316 - acc: 0.6628 - val_loss: 0.9423 - val_acc: 0.5297\n",
      "Epoch 525/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5284 - acc: 0.6609 - val_loss: 0.9428 - val_acc: 0.5344\n",
      "Epoch 526/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5376 - acc: 0.6522 - val_loss: 0.9432 - val_acc: 0.5226\n",
      "Epoch 527/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5310 - acc: 0.6578 - val_loss: 0.9406 - val_acc: 0.5249\n",
      "Epoch 528/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5388 - acc: 0.6578 - val_loss: 0.9228 - val_acc: 0.5297\n",
      "Epoch 529/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5358 - acc: 0.6557 - val_loss: 0.9343 - val_acc: 0.5321\n",
      "Epoch 530/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5371 - acc: 0.6546 - val_loss: 0.9436 - val_acc: 0.5344\n",
      "Epoch 531/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5317 - acc: 0.6620 - val_loss: 0.9396 - val_acc: 0.5344\n",
      "Epoch 532/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5290 - acc: 0.6641 - val_loss: 0.9411 - val_acc: 0.5392\n",
      "Epoch 533/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5284 - acc: 0.6657 - val_loss: 0.9670 - val_acc: 0.5416\n",
      "Epoch 534/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5290 - acc: 0.6654 - val_loss: 0.9770 - val_acc: 0.5368\n",
      "Epoch 535/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5291 - acc: 0.6668 - val_loss: 0.9671 - val_acc: 0.5344\n",
      "Epoch 536/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5321 - acc: 0.6607 - val_loss: 0.9501 - val_acc: 0.5416\n",
      "Epoch 537/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5236 - acc: 0.6705 - val_loss: 0.9604 - val_acc: 0.5368\n",
      "Epoch 538/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.5283 - acc: 0.6646 - val_loss: 0.9648 - val_acc: 0.5439\n",
      "Epoch 539/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5254 - acc: 0.6683 - val_loss: 0.9584 - val_acc: 0.5416\n",
      "Epoch 540/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5290 - acc: 0.6641 - val_loss: 0.9591 - val_acc: 0.5416\n",
      "Epoch 541/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5182 - acc: 0.6757 - val_loss: 0.9798 - val_acc: 0.5534\n",
      "Epoch 542/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5387 - acc: 0.6572 - val_loss: 0.9587 - val_acc: 0.5463\n",
      "Epoch 543/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5338 - acc: 0.6538 - val_loss: 0.9653 - val_acc: 0.5463\n",
      "Epoch 544/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5295 - acc: 0.6557 - val_loss: 0.9549 - val_acc: 0.5511\n",
      "Epoch 545/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5234 - acc: 0.6633 - val_loss: 0.9481 - val_acc: 0.5487\n",
      "Epoch 546/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5339 - acc: 0.6596 - val_loss: 0.9509 - val_acc: 0.5439\n",
      "Epoch 547/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.5359 - acc: 0.6564 - val_loss: 0.9503 - val_acc: 0.5392\n",
      "Epoch 548/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5255 - acc: 0.6562 - val_loss: 0.9620 - val_acc: 0.5487\n",
      "Epoch 549/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5320 - acc: 0.6596 - val_loss: 0.9478 - val_acc: 0.5273\n",
      "Epoch 550/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5216 - acc: 0.6638 - val_loss: 0.9601 - val_acc: 0.5439\n",
      "Epoch 551/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5249 - acc: 0.6657 - val_loss: 0.9666 - val_acc: 0.5368\n",
      "Epoch 552/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5350 - acc: 0.6535 - val_loss: 0.9699 - val_acc: 0.5344\n",
      "Epoch 553/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5170 - acc: 0.6662 - val_loss: 0.9620 - val_acc: 0.5416\n",
      "Epoch 554/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5356 - acc: 0.6575 - val_loss: 0.9578 - val_acc: 0.5344\n",
      "Epoch 555/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5279 - acc: 0.6594 - val_loss: 0.9685 - val_acc: 0.5368\n",
      "Epoch 556/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5249 - acc: 0.6599 - val_loss: 0.9774 - val_acc: 0.5392\n",
      "Epoch 557/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5274 - acc: 0.6617 - val_loss: 0.9915 - val_acc: 0.5368\n",
      "Epoch 558/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5282 - acc: 0.6631 - val_loss: 0.9803 - val_acc: 0.5416\n",
      "Epoch 559/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5238 - acc: 0.6628 - val_loss: 0.9885 - val_acc: 0.5368\n",
      "Epoch 560/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5222 - acc: 0.6644 - val_loss: 0.9796 - val_acc: 0.5439\n",
      "Epoch 561/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5237 - acc: 0.6628 - val_loss: 0.9694 - val_acc: 0.5487\n",
      "Epoch 562/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.5208 - acc: 0.6641 - val_loss: 0.9861 - val_acc: 0.5463\n",
      "Epoch 563/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5315 - acc: 0.6617 - val_loss: 0.9575 - val_acc: 0.5392\n",
      "Epoch 564/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5274 - acc: 0.6594 - val_loss: 0.9670 - val_acc: 0.5368\n",
      "Epoch 565/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.5208 - acc: 0.6607 - val_loss: 0.9792 - val_acc: 0.5226\n",
      "Epoch 566/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5289 - acc: 0.6575 - val_loss: 0.9672 - val_acc: 0.5368\n",
      "Epoch 567/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.5277 - acc: 0.6660 - val_loss: 0.9751 - val_acc: 0.5392\n",
      "Epoch 568/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5283 - acc: 0.6641 - val_loss: 0.9670 - val_acc: 0.5344\n",
      "Epoch 569/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5207 - acc: 0.6641 - val_loss: 0.9636 - val_acc: 0.5368\n",
      "Epoch 570/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5287 - acc: 0.6638 - val_loss: 0.9832 - val_acc: 0.5297\n",
      "Epoch 571/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5279 - acc: 0.6678 - val_loss: 0.9775 - val_acc: 0.5321\n",
      "Epoch 572/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5177 - acc: 0.6739 - val_loss: 0.9759 - val_acc: 0.5321\n",
      "Epoch 573/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5179 - acc: 0.6628 - val_loss: 0.9872 - val_acc: 0.5249\n",
      "Epoch 574/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.5169 - acc: 0.6739 - val_loss: 0.9876 - val_acc: 0.5368\n",
      "Epoch 575/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5232 - acc: 0.6652 - val_loss: 0.9881 - val_acc: 0.5249\n",
      "Epoch 576/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5228 - acc: 0.6620 - val_loss: 0.9656 - val_acc: 0.5321\n",
      "Epoch 577/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5182 - acc: 0.6673 - val_loss: 0.9736 - val_acc: 0.5416\n",
      "Epoch 578/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5255 - acc: 0.6617 - val_loss: 0.9703 - val_acc: 0.5439\n",
      "Epoch 579/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5156 - acc: 0.6747 - val_loss: 0.9754 - val_acc: 0.5487\n",
      "Epoch 580/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5156 - acc: 0.6755 - val_loss: 0.9698 - val_acc: 0.5392\n",
      "Epoch 581/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.5256 - acc: 0.6673 - val_loss: 0.9623 - val_acc: 0.5487\n",
      "Epoch 582/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5225 - acc: 0.6625 - val_loss: 0.9702 - val_acc: 0.5534\n",
      "Epoch 583/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5157 - acc: 0.6657 - val_loss: 0.9855 - val_acc: 0.5487\n",
      "Epoch 584/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5213 - acc: 0.6718 - val_loss: 0.9869 - val_acc: 0.5392\n",
      "Epoch 585/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5132 - acc: 0.6784 - val_loss: 0.9898 - val_acc: 0.5439\n",
      "Epoch 586/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5176 - acc: 0.6691 - val_loss: 0.9961 - val_acc: 0.5463\n",
      "Epoch 587/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5253 - acc: 0.6652 - val_loss: 0.9608 - val_acc: 0.5439\n",
      "Epoch 588/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5234 - acc: 0.6670 - val_loss: 0.9639 - val_acc: 0.5226\n",
      "Epoch 589/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5248 - acc: 0.6617 - val_loss: 0.9750 - val_acc: 0.5368\n",
      "Epoch 590/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5175 - acc: 0.6665 - val_loss: 0.9750 - val_acc: 0.5582\n",
      "Epoch 591/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.5204 - acc: 0.6652 - val_loss: 0.9950 - val_acc: 0.5439\n",
      "Epoch 592/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5194 - acc: 0.6633 - val_loss: 0.9933 - val_acc: 0.5511\n",
      "Epoch 593/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5166 - acc: 0.6771 - val_loss: 0.9984 - val_acc: 0.5439\n",
      "Epoch 594/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5189 - acc: 0.6728 - val_loss: 0.9910 - val_acc: 0.5297\n",
      "Epoch 595/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5095 - acc: 0.6715 - val_loss: 0.9924 - val_acc: 0.5297\n",
      "Epoch 596/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5146 - acc: 0.6757 - val_loss: 0.9888 - val_acc: 0.5416\n",
      "Epoch 597/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5250 - acc: 0.6636 - val_loss: 0.9773 - val_acc: 0.5344\n",
      "Epoch 598/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5182 - acc: 0.6628 - val_loss: 1.0000 - val_acc: 0.5368\n",
      "Epoch 599/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5118 - acc: 0.6731 - val_loss: 0.9946 - val_acc: 0.5463\n",
      "Epoch 600/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5198 - acc: 0.6612 - val_loss: 0.9869 - val_acc: 0.5392\n",
      "Epoch 601/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5192 - acc: 0.6683 - val_loss: 0.9866 - val_acc: 0.5416\n",
      "Epoch 602/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5226 - acc: 0.6668 - val_loss: 0.9935 - val_acc: 0.5344\n",
      "Epoch 603/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5080 - acc: 0.6752 - val_loss: 0.9917 - val_acc: 0.5297\n",
      "Epoch 604/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5134 - acc: 0.6784 - val_loss: 0.9996 - val_acc: 0.5368\n",
      "Epoch 605/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5188 - acc: 0.6623 - val_loss: 1.0001 - val_acc: 0.5368\n",
      "Epoch 606/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5119 - acc: 0.6765 - val_loss: 1.0097 - val_acc: 0.5439\n",
      "Epoch 607/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5141 - acc: 0.6712 - val_loss: 1.0254 - val_acc: 0.5368\n",
      "Epoch 608/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5186 - acc: 0.6670 - val_loss: 1.0022 - val_acc: 0.5368\n",
      "Epoch 609/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5135 - acc: 0.6710 - val_loss: 1.0126 - val_acc: 0.5344\n",
      "Epoch 610/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5210 - acc: 0.6686 - val_loss: 0.9962 - val_acc: 0.5416\n",
      "Epoch 611/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5187 - acc: 0.6681 - val_loss: 1.0033 - val_acc: 0.5368\n",
      "Epoch 612/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5230 - acc: 0.6689 - val_loss: 0.9862 - val_acc: 0.5368\n",
      "Epoch 613/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5163 - acc: 0.6720 - val_loss: 0.9892 - val_acc: 0.5368\n",
      "Epoch 614/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5123 - acc: 0.6705 - val_loss: 0.9956 - val_acc: 0.5344\n",
      "Epoch 615/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5185 - acc: 0.6691 - val_loss: 1.0040 - val_acc: 0.5392\n",
      "Epoch 616/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5158 - acc: 0.6628 - val_loss: 1.0040 - val_acc: 0.5392\n",
      "Epoch 617/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.5071 - acc: 0.6678 - val_loss: 1.0133 - val_acc: 0.5392\n",
      "Epoch 618/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.5223 - acc: 0.6644 - val_loss: 1.0023 - val_acc: 0.5273\n",
      "Epoch 619/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5122 - acc: 0.6654 - val_loss: 1.0101 - val_acc: 0.5368\n",
      "Epoch 620/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5107 - acc: 0.6689 - val_loss: 0.9983 - val_acc: 0.5321\n",
      "Epoch 621/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.5049 - acc: 0.6839 - val_loss: 1.0196 - val_acc: 0.5321\n",
      "Epoch 622/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.5131 - acc: 0.6752 - val_loss: 1.0188 - val_acc: 0.5273\n",
      "Epoch 623/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.5127 - acc: 0.6707 - val_loss: 1.0381 - val_acc: 0.5416\n",
      "Epoch 624/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.5190 - acc: 0.6652 - val_loss: 1.0062 - val_acc: 0.5368\n",
      "Epoch 625/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.5131 - acc: 0.6771 - val_loss: 1.0233 - val_acc: 0.5178\n",
      "Epoch 626/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.5113 - acc: 0.6686 - val_loss: 1.0177 - val_acc: 0.5463\n",
      "Epoch 627/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5105 - acc: 0.6771 - val_loss: 1.0045 - val_acc: 0.5297\n",
      "Epoch 628/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5176 - acc: 0.6686 - val_loss: 1.0151 - val_acc: 0.5321\n",
      "Epoch 629/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5143 - acc: 0.6747 - val_loss: 1.0173 - val_acc: 0.5273\n",
      "Epoch 630/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5117 - acc: 0.6726 - val_loss: 1.0257 - val_acc: 0.5321\n",
      "Epoch 631/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5036 - acc: 0.6768 - val_loss: 1.0262 - val_acc: 0.5249\n",
      "Epoch 632/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5125 - acc: 0.6768 - val_loss: 1.0156 - val_acc: 0.5416\n",
      "Epoch 633/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5091 - acc: 0.6784 - val_loss: 1.0005 - val_acc: 0.5368\n",
      "Epoch 634/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5113 - acc: 0.6694 - val_loss: 1.0221 - val_acc: 0.5392\n",
      "Epoch 635/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5113 - acc: 0.6736 - val_loss: 1.0113 - val_acc: 0.5392\n",
      "Epoch 636/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5122 - acc: 0.6720 - val_loss: 1.0016 - val_acc: 0.5297\n",
      "Epoch 637/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5078 - acc: 0.6779 - val_loss: 1.0103 - val_acc: 0.5297\n",
      "Epoch 638/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5110 - acc: 0.6760 - val_loss: 1.0204 - val_acc: 0.5439\n",
      "Epoch 639/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5176 - acc: 0.6731 - val_loss: 0.9960 - val_acc: 0.5273\n",
      "Epoch 640/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5103 - acc: 0.6736 - val_loss: 1.0175 - val_acc: 0.5249\n",
      "Epoch 641/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5098 - acc: 0.6686 - val_loss: 1.0120 - val_acc: 0.5202\n",
      "Epoch 642/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5094 - acc: 0.6739 - val_loss: 1.0257 - val_acc: 0.5344\n",
      "Epoch 643/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5184 - acc: 0.6715 - val_loss: 1.0050 - val_acc: 0.5249\n",
      "Epoch 644/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5054 - acc: 0.6789 - val_loss: 1.0298 - val_acc: 0.5344\n",
      "Epoch 645/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.5138 - acc: 0.6686 - val_loss: 1.0133 - val_acc: 0.5321\n",
      "Epoch 646/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5051 - acc: 0.6718 - val_loss: 1.0236 - val_acc: 0.5368\n",
      "Epoch 647/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5111 - acc: 0.6697 - val_loss: 1.0062 - val_acc: 0.5321\n",
      "Epoch 648/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5149 - acc: 0.6763 - val_loss: 1.0000 - val_acc: 0.5273\n",
      "Epoch 649/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5076 - acc: 0.6736 - val_loss: 1.0241 - val_acc: 0.5321\n",
      "Epoch 650/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5137 - acc: 0.6691 - val_loss: 1.0019 - val_acc: 0.5273\n",
      "Epoch 651/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5055 - acc: 0.6845 - val_loss: 1.0082 - val_acc: 0.5297\n",
      "Epoch 652/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5019 - acc: 0.6850 - val_loss: 1.0108 - val_acc: 0.5297\n",
      "Epoch 653/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5108 - acc: 0.6757 - val_loss: 1.0175 - val_acc: 0.5368\n",
      "Epoch 654/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5056 - acc: 0.6720 - val_loss: 1.0268 - val_acc: 0.5368\n",
      "Epoch 655/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5085 - acc: 0.6797 - val_loss: 1.0129 - val_acc: 0.5344\n",
      "Epoch 656/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5076 - acc: 0.6779 - val_loss: 1.0374 - val_acc: 0.5344\n",
      "Epoch 657/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5075 - acc: 0.6749 - val_loss: 1.0290 - val_acc: 0.5344\n",
      "Epoch 658/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5031 - acc: 0.6747 - val_loss: 1.0478 - val_acc: 0.5273\n",
      "Epoch 659/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5035 - acc: 0.6749 - val_loss: 1.0335 - val_acc: 0.5154\n",
      "Epoch 660/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5140 - acc: 0.6715 - val_loss: 1.0191 - val_acc: 0.5368\n",
      "Epoch 661/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5090 - acc: 0.6810 - val_loss: 1.0229 - val_acc: 0.5297\n",
      "Epoch 662/1000\n",
      "3784/3784 [==============================] - ETA: 0s - loss: 0.5093 - acc: 0.671 - 1s 226us/step - loss: 0.5094 - acc: 0.6720 - val_loss: 1.0183 - val_acc: 0.5344\n",
      "Epoch 663/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5071 - acc: 0.6789 - val_loss: 1.0326 - val_acc: 0.5344\n",
      "Epoch 664/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5017 - acc: 0.6808 - val_loss: 1.0332 - val_acc: 0.5392\n",
      "Epoch 665/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5031 - acc: 0.6734 - val_loss: 1.0423 - val_acc: 0.5321\n",
      "Epoch 666/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.5051 - acc: 0.6781 - val_loss: 1.0331 - val_acc: 0.5178\n",
      "Epoch 667/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5139 - acc: 0.6665 - val_loss: 0.9964 - val_acc: 0.5344\n",
      "Epoch 668/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5045 - acc: 0.6763 - val_loss: 1.0262 - val_acc: 0.5344\n",
      "Epoch 669/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5020 - acc: 0.6810 - val_loss: 1.0346 - val_acc: 0.5249\n",
      "Epoch 670/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4997 - acc: 0.6800 - val_loss: 1.0487 - val_acc: 0.5368\n",
      "Epoch 671/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4978 - acc: 0.6805 - val_loss: 1.0632 - val_acc: 0.5321\n",
      "Epoch 672/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4973 - acc: 0.6821 - val_loss: 1.0584 - val_acc: 0.5273\n",
      "Epoch 673/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4983 - acc: 0.6810 - val_loss: 1.0613 - val_acc: 0.5439\n",
      "Epoch 674/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5007 - acc: 0.6839 - val_loss: 1.0442 - val_acc: 0.5344\n",
      "Epoch 675/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5139 - acc: 0.6731 - val_loss: 1.0305 - val_acc: 0.5321\n",
      "Epoch 676/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5041 - acc: 0.6773 - val_loss: 1.0399 - val_acc: 0.5249\n",
      "Epoch 677/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4983 - acc: 0.6744 - val_loss: 1.0395 - val_acc: 0.5249\n",
      "Epoch 678/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.5053 - acc: 0.6720 - val_loss: 1.0081 - val_acc: 0.5249\n",
      "Epoch 679/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5014 - acc: 0.6816 - val_loss: 1.0088 - val_acc: 0.5297\n",
      "Epoch 680/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4994 - acc: 0.6834 - val_loss: 1.0407 - val_acc: 0.5368\n",
      "Epoch 681/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4961 - acc: 0.6789 - val_loss: 1.0493 - val_acc: 0.5297\n",
      "Epoch 682/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5008 - acc: 0.6792 - val_loss: 1.0359 - val_acc: 0.5202\n",
      "Epoch 683/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5041 - acc: 0.6776 - val_loss: 1.0188 - val_acc: 0.5297\n",
      "Epoch 684/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5014 - acc: 0.6760 - val_loss: 1.0415 - val_acc: 0.5321\n",
      "Epoch 685/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4988 - acc: 0.6768 - val_loss: 1.0422 - val_acc: 0.5321\n",
      "Epoch 686/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4929 - acc: 0.6786 - val_loss: 1.0321 - val_acc: 0.5439\n",
      "Epoch 687/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4964 - acc: 0.6831 - val_loss: 1.0356 - val_acc: 0.5297\n",
      "Epoch 688/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5039 - acc: 0.6747 - val_loss: 1.0550 - val_acc: 0.5273\n",
      "Epoch 689/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4917 - acc: 0.6823 - val_loss: 1.0810 - val_acc: 0.5344\n",
      "Epoch 690/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4941 - acc: 0.6829 - val_loss: 1.0407 - val_acc: 0.5321\n",
      "Epoch 691/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4941 - acc: 0.6808 - val_loss: 1.0807 - val_acc: 0.5154\n",
      "Epoch 692/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4905 - acc: 0.6895 - val_loss: 1.0604 - val_acc: 0.5368\n",
      "Epoch 693/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4953 - acc: 0.6792 - val_loss: 1.0413 - val_acc: 0.5273\n",
      "Epoch 694/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5072 - acc: 0.6760 - val_loss: 1.0541 - val_acc: 0.5321\n",
      "Epoch 695/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5000 - acc: 0.6863 - val_loss: 1.0542 - val_acc: 0.5321\n",
      "Epoch 696/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4838 - acc: 0.6913 - val_loss: 1.0513 - val_acc: 0.5273\n",
      "Epoch 697/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.5004 - acc: 0.6794 - val_loss: 1.0562 - val_acc: 0.5297\n",
      "Epoch 698/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.4922 - acc: 0.6834 - val_loss: 1.0610 - val_acc: 0.5416\n",
      "Epoch 699/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.4941 - acc: 0.6818 - val_loss: 1.0540 - val_acc: 0.5202\n",
      "Epoch 700/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4977 - acc: 0.6882 - val_loss: 1.0590 - val_acc: 0.5226\n",
      "Epoch 701/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.5001 - acc: 0.6853 - val_loss: 1.0524 - val_acc: 0.5392\n",
      "Epoch 702/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4968 - acc: 0.6839 - val_loss: 1.0495 - val_acc: 0.5487\n",
      "Epoch 703/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4936 - acc: 0.6818 - val_loss: 1.0645 - val_acc: 0.5344\n",
      "Epoch 704/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.5031 - acc: 0.6871 - val_loss: 1.0683 - val_acc: 0.5439\n",
      "Epoch 705/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4941 - acc: 0.6797 - val_loss: 1.0378 - val_acc: 0.5368\n",
      "Epoch 706/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4913 - acc: 0.6845 - val_loss: 1.0496 - val_acc: 0.5297\n",
      "Epoch 707/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4958 - acc: 0.6921 - val_loss: 1.0446 - val_acc: 0.5416\n",
      "Epoch 708/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4869 - acc: 0.6845 - val_loss: 1.0496 - val_acc: 0.5463\n",
      "Epoch 709/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4972 - acc: 0.6890 - val_loss: 1.0219 - val_acc: 0.5416\n",
      "Epoch 710/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4901 - acc: 0.6868 - val_loss: 1.0605 - val_acc: 0.5463\n",
      "Epoch 711/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4995 - acc: 0.6805 - val_loss: 1.0287 - val_acc: 0.5416\n",
      "Epoch 712/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4864 - acc: 0.6884 - val_loss: 1.0367 - val_acc: 0.5368\n",
      "Epoch 713/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.4873 - acc: 0.6884 - val_loss: 1.0629 - val_acc: 0.5511\n",
      "Epoch 714/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.4980 - acc: 0.6755 - val_loss: 1.0467 - val_acc: 0.5463\n",
      "Epoch 715/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.4879 - acc: 0.6916 - val_loss: 1.0710 - val_acc: 0.5368\n",
      "Epoch 716/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.4867 - acc: 0.6874 - val_loss: 1.0587 - val_acc: 0.5344\n",
      "Epoch 717/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.4976 - acc: 0.6771 - val_loss: 1.0546 - val_acc: 0.5392\n",
      "Epoch 718/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.4922 - acc: 0.6876 - val_loss: 1.0653 - val_acc: 0.5392\n",
      "Epoch 719/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.4997 - acc: 0.6802 - val_loss: 1.0290 - val_acc: 0.5463\n",
      "Epoch 720/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.4970 - acc: 0.6784 - val_loss: 1.0273 - val_acc: 0.5321\n",
      "Epoch 721/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4879 - acc: 0.6821 - val_loss: 1.0406 - val_acc: 0.5321\n",
      "Epoch 722/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.4974 - acc: 0.6829 - val_loss: 1.0400 - val_acc: 0.5416\n",
      "Epoch 723/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4945 - acc: 0.6845 - val_loss: 1.0656 - val_acc: 0.5534\n",
      "Epoch 724/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.4943 - acc: 0.6781 - val_loss: 1.0736 - val_acc: 0.5534\n",
      "Epoch 725/1000\n",
      "3784/3784 [==============================] - 1s 240us/step - loss: 0.4896 - acc: 0.6908 - val_loss: 1.0687 - val_acc: 0.5368\n",
      "Epoch 726/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.4954 - acc: 0.6868 - val_loss: 1.0654 - val_acc: 0.5534\n",
      "Epoch 727/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.4917 - acc: 0.6858 - val_loss: 1.0576 - val_acc: 0.5439\n",
      "Epoch 728/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.4807 - acc: 0.6879 - val_loss: 1.0746 - val_acc: 0.5511\n",
      "Epoch 729/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4931 - acc: 0.6860 - val_loss: 1.0673 - val_acc: 0.5416\n",
      "Epoch 730/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.4893 - acc: 0.6908 - val_loss: 1.0698 - val_acc: 0.5439\n",
      "Epoch 731/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.4962 - acc: 0.6786 - val_loss: 1.0345 - val_acc: 0.5344\n",
      "Epoch 732/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.4944 - acc: 0.6771 - val_loss: 1.0581 - val_acc: 0.5226\n",
      "Epoch 733/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.4794 - acc: 0.6956 - val_loss: 1.0885 - val_acc: 0.5439\n",
      "Epoch 734/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.4925 - acc: 0.6842 - val_loss: 1.0693 - val_acc: 0.5368\n",
      "Epoch 735/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.4922 - acc: 0.6834 - val_loss: 1.0585 - val_acc: 0.5368\n",
      "Epoch 736/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.4888 - acc: 0.6895 - val_loss: 1.0509 - val_acc: 0.5416\n",
      "Epoch 737/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.4912 - acc: 0.6855 - val_loss: 1.0651 - val_acc: 0.5439\n",
      "Epoch 738/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.4905 - acc: 0.6839 - val_loss: 1.0518 - val_acc: 0.5344\n",
      "Epoch 739/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4971 - acc: 0.6829 - val_loss: 1.0563 - val_acc: 0.5416\n",
      "Epoch 740/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.4887 - acc: 0.6948 - val_loss: 1.0788 - val_acc: 0.5439\n",
      "Epoch 741/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.4826 - acc: 0.6919 - val_loss: 1.0800 - val_acc: 0.5392\n",
      "Epoch 742/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4890 - acc: 0.6816 - val_loss: 1.0725 - val_acc: 0.5439\n",
      "Epoch 743/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4846 - acc: 0.6908 - val_loss: 1.0577 - val_acc: 0.5297\n",
      "Epoch 744/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.4885 - acc: 0.6916 - val_loss: 1.0683 - val_acc: 0.5297\n",
      "Epoch 745/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4896 - acc: 0.6890 - val_loss: 1.0680 - val_acc: 0.5297\n",
      "Epoch 746/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.4832 - acc: 0.6892 - val_loss: 1.0790 - val_acc: 0.5368\n",
      "Epoch 747/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.4911 - acc: 0.6876 - val_loss: 1.0617 - val_acc: 0.5416\n",
      "Epoch 748/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.4978 - acc: 0.6829 - val_loss: 1.0564 - val_acc: 0.5582\n",
      "Epoch 749/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.4824 - acc: 0.6858 - val_loss: 1.0656 - val_acc: 0.5416\n",
      "Epoch 750/1000\n",
      "3784/3784 [==============================] - ETA: 0s - loss: 0.4760 - acc: 0.691 - 1s 234us/step - loss: 0.4782 - acc: 0.6908 - val_loss: 1.0846 - val_acc: 0.5439\n",
      "Epoch 751/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.4942 - acc: 0.6800 - val_loss: 1.0727 - val_acc: 0.5392\n",
      "Epoch 752/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.4931 - acc: 0.6829 - val_loss: 1.0482 - val_acc: 0.5321\n",
      "Epoch 753/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.4912 - acc: 0.6868 - val_loss: 1.0703 - val_acc: 0.5416\n",
      "Epoch 754/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4946 - acc: 0.6890 - val_loss: 1.0565 - val_acc: 0.5321\n",
      "Epoch 755/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4888 - acc: 0.6911 - val_loss: 1.0777 - val_acc: 0.5463\n",
      "Epoch 756/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.4875 - acc: 0.6842 - val_loss: 1.0854 - val_acc: 0.5368\n",
      "Epoch 757/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.4817 - acc: 0.6942 - val_loss: 1.0949 - val_acc: 0.5344\n",
      "Epoch 758/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.4803 - acc: 0.6987 - val_loss: 1.1131 - val_acc: 0.5392\n",
      "Epoch 759/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4823 - acc: 0.6908 - val_loss: 1.0858 - val_acc: 0.5392\n",
      "Epoch 760/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4812 - acc: 0.6834 - val_loss: 1.0795 - val_acc: 0.5321\n",
      "Epoch 761/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.4941 - acc: 0.6932 - val_loss: 1.0452 - val_acc: 0.5321\n",
      "Epoch 762/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.4856 - acc: 0.6895 - val_loss: 1.0645 - val_acc: 0.5368\n",
      "Epoch 763/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.4752 - acc: 0.6921 - val_loss: 1.0767 - val_acc: 0.5416\n",
      "Epoch 764/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.4808 - acc: 0.6911 - val_loss: 1.0784 - val_acc: 0.5321\n",
      "Epoch 765/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4787 - acc: 0.6945 - val_loss: 1.0909 - val_acc: 0.5368\n",
      "Epoch 766/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.4932 - acc: 0.6876 - val_loss: 1.0778 - val_acc: 0.5321\n",
      "Epoch 767/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.4706 - acc: 0.6956 - val_loss: 1.0974 - val_acc: 0.5439\n",
      "Epoch 768/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.4968 - acc: 0.6813 - val_loss: 1.0845 - val_acc: 0.5321\n",
      "Epoch 769/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4900 - acc: 0.6937 - val_loss: 1.0984 - val_acc: 0.5439\n",
      "Epoch 770/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.4890 - acc: 0.6831 - val_loss: 1.0738 - val_acc: 0.5416\n",
      "Epoch 771/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.4933 - acc: 0.6855 - val_loss: 1.0561 - val_acc: 0.5463\n",
      "Epoch 772/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.4852 - acc: 0.6897 - val_loss: 1.0660 - val_acc: 0.5344\n",
      "Epoch 773/1000\n",
      "3784/3784 [==============================] - 1s 237us/step - loss: 0.4815 - acc: 0.6837 - val_loss: 1.0628 - val_acc: 0.5439\n",
      "Epoch 774/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.4812 - acc: 0.6956 - val_loss: 1.0746 - val_acc: 0.53440s - loss: 0.4804 - acc\n",
      "Epoch 775/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.4900 - acc: 0.6882 - val_loss: 1.0767 - val_acc: 0.5368\n",
      "Epoch 776/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.4813 - acc: 0.6919 - val_loss: 1.0784 - val_acc: 0.5439\n",
      "Epoch 777/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4844 - acc: 0.6921 - val_loss: 1.0728 - val_acc: 0.5439\n",
      "Epoch 778/1000\n",
      "3784/3784 [==============================] - 1s 240us/step - loss: 0.4782 - acc: 0.6892 - val_loss: 1.0889 - val_acc: 0.5416\n",
      "Epoch 779/1000\n",
      "3784/3784 [==============================] - 1s 235us/step - loss: 0.4768 - acc: 0.7011 - val_loss: 1.1039 - val_acc: 0.5511\n",
      "Epoch 780/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.4900 - acc: 0.7016 - val_loss: 1.1014 - val_acc: 0.5511\n",
      "Epoch 781/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4804 - acc: 0.6969 - val_loss: 1.1047 - val_acc: 0.5273\n",
      "Epoch 782/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4762 - acc: 0.6921 - val_loss: 1.1007 - val_acc: 0.5392\n",
      "Epoch 783/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.4966 - acc: 0.6921 - val_loss: 1.0636 - val_acc: 0.5487\n",
      "Epoch 784/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.4783 - acc: 0.6927 - val_loss: 1.0843 - val_acc: 0.5392\n",
      "Epoch 785/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.4802 - acc: 0.6919 - val_loss: 1.0844 - val_acc: 0.5487\n",
      "Epoch 786/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.4758 - acc: 0.6974 - val_loss: 1.0844 - val_acc: 0.5582\n",
      "Epoch 787/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.4741 - acc: 0.6995 - val_loss: 1.0817 - val_acc: 0.5416\n",
      "Epoch 788/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.4800 - acc: 0.6948 - val_loss: 1.0886 - val_acc: 0.5416\n",
      "Epoch 789/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.4822 - acc: 0.6934 - val_loss: 1.0800 - val_acc: 0.5534\n",
      "Epoch 790/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.4836 - acc: 0.6903 - val_loss: 1.0877 - val_acc: 0.5439\n",
      "Epoch 791/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.4846 - acc: 0.6969 - val_loss: 1.0912 - val_acc: 0.5368\n",
      "Epoch 792/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.4748 - acc: 0.6961 - val_loss: 1.0935 - val_acc: 0.5463\n",
      "Epoch 793/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4749 - acc: 0.6982 - val_loss: 1.1085 - val_acc: 0.5463\n",
      "Epoch 794/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.4783 - acc: 0.7001 - val_loss: 1.0961 - val_acc: 0.5416\n",
      "Epoch 795/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.4820 - acc: 0.6845 - val_loss: 1.0895 - val_acc: 0.5416\n",
      "Epoch 796/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.4781 - acc: 0.6940 - val_loss: 1.1057 - val_acc: 0.5392\n",
      "Epoch 797/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.4739 - acc: 0.6961 - val_loss: 1.1183 - val_acc: 0.5344\n",
      "Epoch 798/1000\n",
      "3784/3784 [==============================] - 1s 236us/step - loss: 0.4859 - acc: 0.6934 - val_loss: 1.1151 - val_acc: 0.5416\n",
      "Epoch 799/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4773 - acc: 0.7014 - val_loss: 1.1376 - val_acc: 0.5392\n",
      "Epoch 800/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.4843 - acc: 0.6937 - val_loss: 1.1206 - val_acc: 0.5487\n",
      "Epoch 801/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.4882 - acc: 0.6921 - val_loss: 1.1064 - val_acc: 0.5416\n",
      "Epoch 802/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.4809 - acc: 0.6919 - val_loss: 1.1050 - val_acc: 0.5439\n",
      "Epoch 803/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4766 - acc: 0.6945 - val_loss: 1.0984 - val_acc: 0.5558\n",
      "Epoch 804/1000\n",
      "3784/3784 [==============================] - 1s 237us/step - loss: 0.4798 - acc: 0.6956 - val_loss: 1.0761 - val_acc: 0.5368\n",
      "Epoch 805/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.4735 - acc: 0.6956 - val_loss: 1.0934 - val_acc: 0.5463\n",
      "Epoch 806/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4719 - acc: 0.6940 - val_loss: 1.1046 - val_acc: 0.5487\n",
      "Epoch 807/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.4785 - acc: 0.6956 - val_loss: 1.1083 - val_acc: 0.5534\n",
      "Epoch 808/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.4729 - acc: 0.6897 - val_loss: 1.0966 - val_acc: 0.5511\n",
      "Epoch 809/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.4734 - acc: 0.6937 - val_loss: 1.0870 - val_acc: 0.5439\n",
      "Epoch 810/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.4682 - acc: 0.7045 - val_loss: 1.1026 - val_acc: 0.5439\n",
      "Epoch 811/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.4748 - acc: 0.6995 - val_loss: 1.1137 - val_acc: 0.5487\n",
      "Epoch 812/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4794 - acc: 0.7035 - val_loss: 1.1023 - val_acc: 0.5392\n",
      "Epoch 813/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4786 - acc: 0.6979 - val_loss: 1.0925 - val_acc: 0.5416\n",
      "Epoch 814/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.4646 - acc: 0.7064 - val_loss: 1.0953 - val_acc: 0.5416\n",
      "Epoch 815/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.4655 - acc: 0.7014 - val_loss: 1.1162 - val_acc: 0.5321\n",
      "Epoch 816/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4869 - acc: 0.6908 - val_loss: 1.1152 - val_acc: 0.5392\n",
      "Epoch 817/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4651 - acc: 0.6995 - val_loss: 1.1216 - val_acc: 0.5321\n",
      "Epoch 818/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.4750 - acc: 0.6927 - val_loss: 1.1217 - val_acc: 0.5487\n",
      "Epoch 819/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.4702 - acc: 0.6903 - val_loss: 1.0929 - val_acc: 0.5321\n",
      "Epoch 820/1000\n",
      "3784/3784 [==============================] - 1s 233us/step - loss: 0.4690 - acc: 0.7027 - val_loss: 1.0938 - val_acc: 0.5392\n",
      "Epoch 821/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.4735 - acc: 0.6948 - val_loss: 1.1101 - val_acc: 0.5344\n",
      "Epoch 822/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4627 - acc: 0.7032 - val_loss: 1.1362 - val_acc: 0.5534\n",
      "Epoch 823/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4647 - acc: 0.7038 - val_loss: 1.1341 - val_acc: 0.5463\n",
      "Epoch 824/1000\n",
      "3784/3784 [==============================] - 1s 229us/step - loss: 0.4743 - acc: 0.6897 - val_loss: 1.1268 - val_acc: 0.5368\n",
      "Epoch 825/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4736 - acc: 0.6964 - val_loss: 1.1250 - val_acc: 0.5463\n",
      "Epoch 826/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4758 - acc: 0.7038 - val_loss: 1.1227 - val_acc: 0.5534\n",
      "Epoch 827/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4710 - acc: 0.6945 - val_loss: 1.0844 - val_acc: 0.5487\n",
      "Epoch 828/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4780 - acc: 0.6945 - val_loss: 1.1029 - val_acc: 0.5463\n",
      "Epoch 829/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4749 - acc: 0.6948 - val_loss: 1.1039 - val_acc: 0.5487\n",
      "Epoch 830/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4744 - acc: 0.6948 - val_loss: 1.0985 - val_acc: 0.5511\n",
      "Epoch 831/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4737 - acc: 0.6995 - val_loss: 1.0965 - val_acc: 0.5463\n",
      "Epoch 832/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4676 - acc: 0.7053 - val_loss: 1.1008 - val_acc: 0.5463\n",
      "Epoch 833/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4743 - acc: 0.6995 - val_loss: 1.1019 - val_acc: 0.5534\n",
      "Epoch 834/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4805 - acc: 0.6927 - val_loss: 1.1025 - val_acc: 0.5439\n",
      "Epoch 835/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4819 - acc: 0.6921 - val_loss: 1.1008 - val_acc: 0.5368\n",
      "Epoch 836/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4757 - acc: 0.6985 - val_loss: 1.1071 - val_acc: 0.5344\n",
      "Epoch 837/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4790 - acc: 0.6956 - val_loss: 1.1057 - val_acc: 0.5368\n",
      "Epoch 838/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4658 - acc: 0.6971 - val_loss: 1.1006 - val_acc: 0.5558\n",
      "Epoch 839/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4640 - acc: 0.7032 - val_loss: 1.1027 - val_acc: 0.5416\n",
      "Epoch 840/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4628 - acc: 0.7106 - val_loss: 1.1141 - val_acc: 0.5439\n",
      "Epoch 841/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4732 - acc: 0.7019 - val_loss: 1.1267 - val_acc: 0.5463\n",
      "Epoch 842/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.4853 - acc: 0.6940 - val_loss: 1.1173 - val_acc: 0.5368\n",
      "Epoch 843/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4716 - acc: 0.6974 - val_loss: 1.1240 - val_acc: 0.5511\n",
      "Epoch 844/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4756 - acc: 0.6966 - val_loss: 1.1346 - val_acc: 0.5606\n",
      "Epoch 845/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4764 - acc: 0.6971 - val_loss: 1.1272 - val_acc: 0.5344\n",
      "Epoch 846/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4729 - acc: 0.6995 - val_loss: 1.1320 - val_acc: 0.5511\n",
      "Epoch 847/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4635 - acc: 0.7019 - val_loss: 1.1185 - val_acc: 0.5368\n",
      "Epoch 848/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4710 - acc: 0.6987 - val_loss: 1.1437 - val_acc: 0.5392\n",
      "Epoch 849/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4672 - acc: 0.7024 - val_loss: 1.1325 - val_acc: 0.5463\n",
      "Epoch 850/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4690 - acc: 0.6993 - val_loss: 1.1213 - val_acc: 0.5511\n",
      "Epoch 851/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4709 - acc: 0.6998 - val_loss: 1.1342 - val_acc: 0.5487\n",
      "Epoch 852/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4657 - acc: 0.6969 - val_loss: 1.1371 - val_acc: 0.5463\n",
      "Epoch 853/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4707 - acc: 0.7006 - val_loss: 1.1208 - val_acc: 0.5439\n",
      "Epoch 854/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4655 - acc: 0.7048 - val_loss: 1.1304 - val_acc: 0.5487\n",
      "Epoch 855/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4803 - acc: 0.6987 - val_loss: 1.1072 - val_acc: 0.5606\n",
      "Epoch 856/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4755 - acc: 0.6929 - val_loss: 1.1140 - val_acc: 0.5392\n",
      "Epoch 857/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4739 - acc: 0.6908 - val_loss: 1.1142 - val_acc: 0.5321\n",
      "Epoch 858/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4584 - acc: 0.7093 - val_loss: 1.1324 - val_acc: 0.5416\n",
      "Epoch 859/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4674 - acc: 0.7022 - val_loss: 1.1313 - val_acc: 0.5416\n",
      "Epoch 860/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4615 - acc: 0.7119 - val_loss: 1.1325 - val_acc: 0.5487\n",
      "Epoch 861/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4613 - acc: 0.7051 - val_loss: 1.1193 - val_acc: 0.5487\n",
      "Epoch 862/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4625 - acc: 0.7038 - val_loss: 1.1392 - val_acc: 0.5534\n",
      "Epoch 863/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4603 - acc: 0.7056 - val_loss: 1.1443 - val_acc: 0.5321\n",
      "Epoch 864/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4776 - acc: 0.6924 - val_loss: 1.1174 - val_acc: 0.5368\n",
      "Epoch 865/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4760 - acc: 0.6987 - val_loss: 1.1272 - val_acc: 0.5344\n",
      "Epoch 866/1000\n",
      "3784/3784 [==============================] - 1s 223us/step - loss: 0.4639 - acc: 0.7030 - val_loss: 1.1312 - val_acc: 0.5439\n",
      "Epoch 867/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4617 - acc: 0.7014 - val_loss: 1.0995 - val_acc: 0.5439\n",
      "Epoch 868/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4657 - acc: 0.7030 - val_loss: 1.1178 - val_acc: 0.5487\n",
      "Epoch 869/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4599 - acc: 0.7048 - val_loss: 1.1231 - val_acc: 0.5582\n",
      "Epoch 870/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4719 - acc: 0.6982 - val_loss: 1.1161 - val_acc: 0.5487\n",
      "Epoch 871/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4590 - acc: 0.7114 - val_loss: 1.1229 - val_acc: 0.5511\n",
      "Epoch 872/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4577 - acc: 0.7170 - val_loss: 1.1320 - val_acc: 0.5511\n",
      "Epoch 873/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4643 - acc: 0.7045 - val_loss: 1.1289 - val_acc: 0.5582\n",
      "Epoch 874/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4634 - acc: 0.7096 - val_loss: 1.1342 - val_acc: 0.5534\n",
      "Epoch 875/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4637 - acc: 0.7040 - val_loss: 1.1411 - val_acc: 0.5534\n",
      "Epoch 876/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.4621 - acc: 0.7024 - val_loss: 1.1565 - val_acc: 0.5534\n",
      "Epoch 877/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4599 - acc: 0.7112 - val_loss: 1.1541 - val_acc: 0.5487\n",
      "Epoch 878/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4555 - acc: 0.7119 - val_loss: 1.1309 - val_acc: 0.5439\n",
      "Epoch 879/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4571 - acc: 0.7059 - val_loss: 1.1396 - val_acc: 0.5487\n",
      "Epoch 880/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4764 - acc: 0.6990 - val_loss: 1.1145 - val_acc: 0.5558\n",
      "Epoch 881/1000\n",
      "3784/3784 [==============================] - 1s 223us/step - loss: 0.4744 - acc: 0.7008 - val_loss: 1.1422 - val_acc: 0.5463\n",
      "Epoch 882/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4609 - acc: 0.7022 - val_loss: 1.1439 - val_acc: 0.5511\n",
      "Epoch 883/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4623 - acc: 0.7090 - val_loss: 1.1494 - val_acc: 0.5368\n",
      "Epoch 884/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4718 - acc: 0.6998 - val_loss: 1.1208 - val_acc: 0.5629\n",
      "Epoch 885/1000\n",
      "3784/3784 [==============================] - 1s 231us/step - loss: 0.4602 - acc: 0.7098 - val_loss: 1.1394 - val_acc: 0.5629\n",
      "Epoch 886/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4633 - acc: 0.7085 - val_loss: 1.1244 - val_acc: 0.5534\n",
      "Epoch 887/1000\n",
      "3784/3784 [==============================] - 1s 223us/step - loss: 0.4713 - acc: 0.7032 - val_loss: 1.1150 - val_acc: 0.5534\n",
      "Epoch 888/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4680 - acc: 0.6995 - val_loss: 1.1250 - val_acc: 0.5511\n",
      "Epoch 889/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4551 - acc: 0.7117 - val_loss: 1.1575 - val_acc: 0.5558\n",
      "Epoch 890/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4711 - acc: 0.7090 - val_loss: 1.1466 - val_acc: 0.5487\n",
      "Epoch 891/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4580 - acc: 0.7082 - val_loss: 1.1405 - val_acc: 0.5534\n",
      "Epoch 892/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4654 - acc: 0.7016 - val_loss: 1.1273 - val_acc: 0.5511\n",
      "Epoch 893/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4609 - acc: 0.7048 - val_loss: 1.1298 - val_acc: 0.5463\n",
      "Epoch 894/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4532 - acc: 0.7090 - val_loss: 1.1298 - val_acc: 0.5416\n",
      "Epoch 895/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.4634 - acc: 0.7016 - val_loss: 1.1347 - val_acc: 0.5511\n",
      "Epoch 896/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.4591 - acc: 0.7154 - val_loss: 1.1552 - val_acc: 0.5439\n",
      "Epoch 897/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4546 - acc: 0.7093 - val_loss: 1.1718 - val_acc: 0.5511\n",
      "Epoch 898/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4630 - acc: 0.7135 - val_loss: 1.1527 - val_acc: 0.5463\n",
      "Epoch 899/1000\n",
      "3784/3784 [==============================] - 1s 223us/step - loss: 0.4763 - acc: 0.6993 - val_loss: 1.1220 - val_acc: 0.5439\n",
      "Epoch 900/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4697 - acc: 0.7008 - val_loss: 1.1221 - val_acc: 0.5558\n",
      "Epoch 901/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4626 - acc: 0.7130 - val_loss: 1.1334 - val_acc: 0.5534\n",
      "Epoch 902/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4652 - acc: 0.7067 - val_loss: 1.1408 - val_acc: 0.5487\n",
      "Epoch 903/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4629 - acc: 0.7067 - val_loss: 1.1401 - val_acc: 0.5416\n",
      "Epoch 904/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4683 - acc: 0.7027 - val_loss: 1.1416 - val_acc: 0.5534\n",
      "Epoch 905/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4697 - acc: 0.7003 - val_loss: 1.1334 - val_acc: 0.5511\n",
      "Epoch 906/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4631 - acc: 0.6987 - val_loss: 1.1525 - val_acc: 0.5511\n",
      "Epoch 907/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4621 - acc: 0.7149 - val_loss: 1.1490 - val_acc: 0.5487\n",
      "Epoch 908/1000\n",
      "3784/3784 [==============================] - 1s 223us/step - loss: 0.4580 - acc: 0.7080 - val_loss: 1.1614 - val_acc: 0.5534\n",
      "Epoch 909/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4594 - acc: 0.7038 - val_loss: 1.1405 - val_acc: 0.5534\n",
      "Epoch 910/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4622 - acc: 0.7030 - val_loss: 1.1415 - val_acc: 0.5439\n",
      "Epoch 911/1000\n",
      "3784/3784 [==============================] - 1s 223us/step - loss: 0.4571 - acc: 0.7032 - val_loss: 1.1504 - val_acc: 0.5487\n",
      "Epoch 912/1000\n",
      "3784/3784 [==============================] - 1s 230us/step - loss: 0.4467 - acc: 0.7164 - val_loss: 1.1494 - val_acc: 0.5463\n",
      "Epoch 913/1000\n",
      "3784/3784 [==============================] - 1s 223us/step - loss: 0.4647 - acc: 0.7038 - val_loss: 1.1391 - val_acc: 0.5463\n",
      "Epoch 914/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.4640 - acc: 0.7016 - val_loss: 1.1508 - val_acc: 0.5558\n",
      "Epoch 915/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4551 - acc: 0.7125 - val_loss: 1.1731 - val_acc: 0.5463\n",
      "Epoch 916/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4584 - acc: 0.7119 - val_loss: 1.1267 - val_acc: 0.5416\n",
      "Epoch 917/1000\n",
      "3784/3784 [==============================] - 1s 223us/step - loss: 0.4627 - acc: 0.7032 - val_loss: 1.1331 - val_acc: 0.5582\n",
      "Epoch 918/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4557 - acc: 0.7080 - val_loss: 1.1453 - val_acc: 0.5439\n",
      "Epoch 919/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4524 - acc: 0.7106 - val_loss: 1.1728 - val_acc: 0.5487\n",
      "Epoch 920/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4538 - acc: 0.7122 - val_loss: 1.1510 - val_acc: 0.5439\n",
      "Epoch 921/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4548 - acc: 0.7098 - val_loss: 1.1496 - val_acc: 0.5416\n",
      "Epoch 922/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4593 - acc: 0.7090 - val_loss: 1.1545 - val_acc: 0.5487\n",
      "Epoch 923/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4613 - acc: 0.7112 - val_loss: 1.1365 - val_acc: 0.5582\n",
      "Epoch 924/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4644 - acc: 0.7011 - val_loss: 1.1589 - val_acc: 0.5273\n",
      "Epoch 925/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4601 - acc: 0.7075 - val_loss: 1.1579 - val_acc: 0.5416\n",
      "Epoch 926/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4487 - acc: 0.7170 - val_loss: 1.1705 - val_acc: 0.5344\n",
      "Epoch 927/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4587 - acc: 0.7146 - val_loss: 1.1767 - val_acc: 0.5511\n",
      "Epoch 928/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4556 - acc: 0.7109 - val_loss: 1.1813 - val_acc: 0.5534\n",
      "Epoch 929/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4621 - acc: 0.7090 - val_loss: 1.1784 - val_acc: 0.5439\n",
      "Epoch 930/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4552 - acc: 0.7101 - val_loss: 1.1691 - val_acc: 0.5463\n",
      "Epoch 931/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4562 - acc: 0.7151 - val_loss: 1.1745 - val_acc: 0.5463\n",
      "Epoch 932/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4548 - acc: 0.7090 - val_loss: 1.1293 - val_acc: 0.5487\n",
      "Epoch 933/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4643 - acc: 0.7035 - val_loss: 1.1450 - val_acc: 0.5606\n",
      "Epoch 934/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4517 - acc: 0.7067 - val_loss: 1.1397 - val_acc: 0.5558\n",
      "Epoch 935/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4628 - acc: 0.7093 - val_loss: 1.1412 - val_acc: 0.5534\n",
      "Epoch 936/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4524 - acc: 0.7125 - val_loss: 1.1540 - val_acc: 0.5439\n",
      "Epoch 937/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4548 - acc: 0.7125 - val_loss: 1.1621 - val_acc: 0.5487\n",
      "Epoch 938/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4548 - acc: 0.7119 - val_loss: 1.1506 - val_acc: 0.5416\n",
      "Epoch 939/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.4635 - acc: 0.7024 - val_loss: 1.1357 - val_acc: 0.5463\n",
      "Epoch 940/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4463 - acc: 0.7093 - val_loss: 1.1544 - val_acc: 0.5463\n",
      "Epoch 941/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4531 - acc: 0.7101 - val_loss: 1.1516 - val_acc: 0.5534\n",
      "Epoch 942/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4520 - acc: 0.7172 - val_loss: 1.1653 - val_acc: 0.5463\n",
      "Epoch 943/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4402 - acc: 0.7178 - val_loss: 1.1513 - val_acc: 0.5463\n",
      "Epoch 944/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4491 - acc: 0.7077 - val_loss: 1.1691 - val_acc: 0.5511\n",
      "Epoch 945/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4459 - acc: 0.7112 - val_loss: 1.1652 - val_acc: 0.5368\n",
      "Epoch 946/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4561 - acc: 0.7119 - val_loss: 1.1940 - val_acc: 0.5416\n",
      "Epoch 947/1000\n",
      "3784/3784 [==============================] - 1s 223us/step - loss: 0.4551 - acc: 0.7082 - val_loss: 1.1632 - val_acc: 0.5392\n",
      "Epoch 948/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4536 - acc: 0.7043 - val_loss: 1.1765 - val_acc: 0.5582\n",
      "Epoch 949/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4566 - acc: 0.7167 - val_loss: 1.1931 - val_acc: 0.5487\n",
      "Epoch 950/1000\n",
      "3784/3784 [==============================] - 1s 223us/step - loss: 0.4560 - acc: 0.7130 - val_loss: 1.1682 - val_acc: 0.5439\n",
      "Epoch 951/1000\n",
      "3784/3784 [==============================] - 1s 223us/step - loss: 0.4590 - acc: 0.7146 - val_loss: 1.1505 - val_acc: 0.5511\n",
      "Epoch 952/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4536 - acc: 0.7061 - val_loss: 1.1502 - val_acc: 0.5487\n",
      "Epoch 953/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4599 - acc: 0.7048 - val_loss: 1.1465 - val_acc: 0.5629\n",
      "Epoch 954/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4541 - acc: 0.7106 - val_loss: 1.1659 - val_acc: 0.5582\n",
      "Epoch 955/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4563 - acc: 0.7130 - val_loss: 1.1428 - val_acc: 0.5463\n",
      "Epoch 956/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4451 - acc: 0.7117 - val_loss: 1.1861 - val_acc: 0.5368\n",
      "Epoch 957/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4586 - acc: 0.7043 - val_loss: 1.1740 - val_acc: 0.5368\n",
      "Epoch 958/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4545 - acc: 0.7112 - val_loss: 1.1608 - val_acc: 0.5439\n",
      "Epoch 959/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4503 - acc: 0.7154 - val_loss: 1.1847 - val_acc: 0.5463\n",
      "Epoch 960/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4567 - acc: 0.7019 - val_loss: 1.1584 - val_acc: 0.5368\n",
      "Epoch 961/1000\n",
      "3784/3784 [==============================] - 1s 223us/step - loss: 0.4631 - acc: 0.7011 - val_loss: 1.1449 - val_acc: 0.5273\n",
      "Epoch 962/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4629 - acc: 0.7075 - val_loss: 1.1544 - val_acc: 0.5344\n",
      "Epoch 963/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4624 - acc: 0.7056 - val_loss: 1.1684 - val_acc: 0.5368\n",
      "Epoch 964/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4562 - acc: 0.7090 - val_loss: 1.1807 - val_acc: 0.5297\n",
      "Epoch 965/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4469 - acc: 0.7207 - val_loss: 1.2061 - val_acc: 0.5344\n",
      "Epoch 966/1000\n",
      "3784/3784 [==============================] - 1s 234us/step - loss: 0.4504 - acc: 0.7143 - val_loss: 1.1968 - val_acc: 0.5511\n",
      "Epoch 967/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4527 - acc: 0.7138 - val_loss: 1.1998 - val_acc: 0.5439\n",
      "Epoch 968/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4454 - acc: 0.7154 - val_loss: 1.2185 - val_acc: 0.5368\n",
      "Epoch 969/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4523 - acc: 0.7109 - val_loss: 1.1758 - val_acc: 0.5321\n",
      "Epoch 970/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4513 - acc: 0.7151 - val_loss: 1.1643 - val_acc: 0.5344\n",
      "Epoch 971/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4524 - acc: 0.7178 - val_loss: 1.1882 - val_acc: 0.5392\n",
      "Epoch 972/1000\n",
      "3784/3784 [==============================] - 1s 228us/step - loss: 0.4452 - acc: 0.7199 - val_loss: 1.1883 - val_acc: 0.5392\n",
      "Epoch 973/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4583 - acc: 0.7080 - val_loss: 1.1704 - val_acc: 0.5368\n",
      "Epoch 974/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4495 - acc: 0.7143 - val_loss: 1.1773 - val_acc: 0.5392\n",
      "Epoch 975/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4639 - acc: 0.7082 - val_loss: 1.1729 - val_acc: 0.5392\n",
      "Epoch 976/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4583 - acc: 0.7080 - val_loss: 1.1956 - val_acc: 0.5439\n",
      "Epoch 977/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4529 - acc: 0.7048 - val_loss: 1.1699 - val_acc: 0.5297\n",
      "Epoch 978/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4438 - acc: 0.7207 - val_loss: 1.1926 - val_acc: 0.5439\n",
      "Epoch 979/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4445 - acc: 0.7133 - val_loss: 1.1875 - val_acc: 0.5249\n",
      "Epoch 980/1000\n",
      "3784/3784 [==============================] - 1s 223us/step - loss: 0.4644 - acc: 0.7059 - val_loss: 1.1434 - val_acc: 0.5463\n",
      "Epoch 981/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4432 - acc: 0.7191 - val_loss: 1.1793 - val_acc: 0.5321\n",
      "Epoch 982/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4534 - acc: 0.7119 - val_loss: 1.1671 - val_acc: 0.5344\n",
      "Epoch 983/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4491 - acc: 0.7141 - val_loss: 1.1718 - val_acc: 0.5487\n",
      "Epoch 984/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4563 - acc: 0.7143 - val_loss: 1.1628 - val_acc: 0.5321\n",
      "Epoch 985/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4434 - acc: 0.7164 - val_loss: 1.1728 - val_acc: 0.5344\n",
      "Epoch 986/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4424 - acc: 0.7204 - val_loss: 1.1978 - val_acc: 0.5463\n",
      "Epoch 987/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4502 - acc: 0.7175 - val_loss: 1.1684 - val_acc: 0.5463\n",
      "Epoch 988/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4483 - acc: 0.7093 - val_loss: 1.1821 - val_acc: 0.5487\n",
      "Epoch 989/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4537 - acc: 0.7125 - val_loss: 1.1588 - val_acc: 0.5344\n",
      "Epoch 990/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4356 - acc: 0.7228 - val_loss: 1.1750 - val_acc: 0.5463\n",
      "Epoch 991/1000\n",
      "3784/3784 [==============================] - 1s 222us/step - loss: 0.4402 - acc: 0.7196 - val_loss: 1.1885 - val_acc: 0.5558\n",
      "Epoch 992/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4499 - acc: 0.7088 - val_loss: 1.1552 - val_acc: 0.5558\n",
      "Epoch 993/1000\n",
      "3784/3784 [==============================] - 1s 232us/step - loss: 0.4533 - acc: 0.7151 - val_loss: 1.1571 - val_acc: 0.5463\n",
      "Epoch 994/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4430 - acc: 0.7270 - val_loss: 1.1804 - val_acc: 0.5439\n",
      "Epoch 995/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4579 - acc: 0.7109 - val_loss: 1.1530 - val_acc: 0.5368\n",
      "Epoch 996/1000\n",
      "3784/3784 [==============================] - 1s 224us/step - loss: 0.4498 - acc: 0.7040 - val_loss: 1.1599 - val_acc: 0.5511\n",
      "Epoch 997/1000\n",
      "3784/3784 [==============================] - 1s 227us/step - loss: 0.4540 - acc: 0.7059 - val_loss: 1.1737 - val_acc: 0.5487\n",
      "Epoch 998/1000\n",
      "3784/3784 [==============================] - 1s 226us/step - loss: 0.4528 - acc: 0.7093 - val_loss: 1.1569 - val_acc: 0.5368\n",
      "Epoch 999/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4513 - acc: 0.7188 - val_loss: 1.1565 - val_acc: 0.5463\n",
      "Epoch 1000/1000\n",
      "3784/3784 [==============================] - 1s 225us/step - loss: 0.4526 - acc: 0.7119 - val_loss: 1.1618 - val_acc: 0.5463\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 0.00002\n",
    "history = model.fit(train_X, train_y, epochs=1000, batch_size=128, validation_split=0.1, verbose=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3474 samples, validate on 387 samples\n",
      "Epoch 1/100\n",
      "3474/3474 [==============================] - 7s 2ms/step - loss: 4.0286 - val_loss: 0.0710\n",
      "Epoch 2/100\n",
      "3474/3474 [==============================] - 2s 630us/step - loss: 0.0389 - val_loss: 0.0773\n",
      "Epoch 3/100\n",
      "3474/3474 [==============================] - 2s 633us/step - loss: 0.0122 - val_loss: 0.0375\n",
      "Epoch 4/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 0.0074 - val_loss: 0.0273\n",
      "Epoch 5/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 0.0047 - val_loss: 0.0160\n",
      "Epoch 6/100\n",
      "3474/3474 [==============================] - 2s 629us/step - loss: 0.0057 - val_loss: 0.0019\n",
      "Epoch 7/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 0.0042 - val_loss: 0.0092\n",
      "Epoch 8/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 9/100\n",
      "3474/3474 [==============================] - 2s 638us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 10/100\n",
      "3474/3474 [==============================] - 2s 635us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 11/100\n",
      "3474/3474 [==============================] - 2s 627us/step - loss: 0.0052 - val_loss: 7.2526e-04\n",
      "Epoch 12/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 0.0018 - val_loss: 7.4290e-04\n",
      "Epoch 13/100\n",
      "3474/3474 [==============================] - 2s 633us/step - loss: 0.0061 - val_loss: 0.0028\n",
      "Epoch 14/100\n",
      "3474/3474 [==============================] - 2s 629us/step - loss: 0.0046 - val_loss: 0.0074\n",
      "Epoch 15/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 16/100\n",
      "3474/3474 [==============================] - 2s 629us/step - loss: 0.0012 - val_loss: 0.0025\n",
      "Epoch 17/100\n",
      "3474/3474 [==============================] - 2s 630us/step - loss: 0.0047 - val_loss: 0.0013\n",
      "Epoch 18/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 0.0041 - val_loss: 5.0134e-04\n",
      "Epoch 19/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 4.5151e-04 - val_loss: 3.7833e-04\n",
      "Epoch 20/100\n",
      "3474/3474 [==============================] - 2s 639us/step - loss: 0.0046 - val_loss: 0.0020\n",
      "Epoch 21/100\n",
      "3474/3474 [==============================] - 2s 630us/step - loss: 8.2054e-04 - val_loss: 3.1786e-04\n",
      "Epoch 22/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 7.8377e-04 - val_loss: 3.6461e-04\n",
      "Epoch 23/100\n",
      "3474/3474 [==============================] - 2s 643us/step - loss: 0.0082 - val_loss: 0.0037\n",
      "Epoch 24/100\n",
      "3474/3474 [==============================] - 2s 643us/step - loss: 0.0017 - val_loss: 4.0460e-04\n",
      "Epoch 25/100\n",
      "3474/3474 [==============================] - 2s 633us/step - loss: 5.8267e-04 - val_loss: 0.0013\n",
      "Epoch 26/100\n",
      "3474/3474 [==============================] - 2s 635us/step - loss: 6.8093e-04 - val_loss: 4.7002e-04\n",
      "Epoch 27/100\n",
      "3474/3474 [==============================] - 2s 636us/step - loss: 0.0011 - val_loss: 0.0080\n",
      "Epoch 28/100\n",
      "3474/3474 [==============================] - 2s 636us/step - loss: 0.0073 - val_loss: 8.5657e-04\n",
      "Epoch 29/100\n",
      "3474/3474 [==============================] - 2s 633us/step - loss: 4.5322e-04 - val_loss: 3.9678e-04\n",
      "Epoch 30/100\n",
      "3474/3474 [==============================] - 2s 641us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Epoch 31/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 0.0016 - val_loss: 6.3618e-04\n",
      "Epoch 32/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 0.0010 - val_loss: 0.0059\n",
      "Epoch 33/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 0.0049 - val_loss: 0.0022\n",
      "Epoch 34/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 0.0041 - val_loss: 5.5118e-04\n",
      "Epoch 35/100\n",
      "3474/3474 [==============================] - 2s 628us/step - loss: 8.2320e-04 - val_loss: 2.9770e-04\n",
      "Epoch 36/100\n",
      "3474/3474 [==============================] - 2s 635us/step - loss: 3.5537e-04 - val_loss: 6.0331e-04\n",
      "Epoch 37/100\n",
      "3474/3474 [==============================] - 2s 628us/step - loss: 7.7914e-04 - val_loss: 0.0022\n",
      "Epoch 38/100\n",
      "3474/3474 [==============================] - 2s 629us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 39/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 9.1433e-04 - val_loss: 0.0027\n",
      "Epoch 40/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 41/100\n",
      "3474/3474 [==============================] - 2s 635us/step - loss: 8.5682e-04 - val_loss: 7.4247e-04\n",
      "Epoch 42/100\n",
      "3474/3474 [==============================] - 2s 633us/step - loss: 0.0025 - val_loss: 0.0198\n",
      "Epoch 43/100\n",
      "3474/3474 [==============================] - 2s 630us/step - loss: 0.0041 - val_loss: 7.1470e-04\n",
      "Epoch 44/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 3.3732e-04 - val_loss: 9.0464e-04\n",
      "Epoch 45/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 7.0917e-04 - val_loss: 6.9511e-04\n",
      "Epoch 46/100\n",
      "3474/3474 [==============================] - 2s 629us/step - loss: 9.0771e-04 - val_loss: 0.0025\n",
      "Epoch 47/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 0.0024 - val_loss: 0.0094\n",
      "Epoch 48/100\n",
      "3474/3474 [==============================] - 2s 629us/step - loss: 0.0017 - val_loss: 2.2103e-04\n",
      "Epoch 49/100\n",
      "3474/3474 [==============================] - 2s 629us/step - loss: 5.8662e-04 - val_loss: 0.0057\n",
      "Epoch 50/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 0.0111 - val_loss: 0.0033\n",
      "Epoch 51/100\n",
      "3474/3474 [==============================] - 2s 638us/step - loss: 0.0046 - val_loss: 2.9069e-04\n",
      "Epoch 52/100\n",
      "3474/3474 [==============================] - 2s 643us/step - loss: 3.1304e-04 - val_loss: 3.2297e-04\n",
      "Epoch 53/100\n",
      "3474/3474 [==============================] - 2s 639us/step - loss: 3.9436e-04 - val_loss: 3.9248e-04\n",
      "Epoch 54/100\n",
      "3474/3474 [==============================] - 2s 633us/step - loss: 3.2373e-04 - val_loss: 2.2640e-04\n",
      "Epoch 55/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 1.4481e-04 - val_loss: 2.3411e-04\n",
      "Epoch 56/100\n",
      "3474/3474 [==============================] - 2s 638us/step - loss: 0.0054 - val_loss: 2.8865e-04\n",
      "Epoch 57/100\n",
      "3474/3474 [==============================] - 2s 635us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 58/100\n",
      "3474/3474 [==============================] - 2s 633us/step - loss: 3.3324e-04 - val_loss: 2.0896e-04\n",
      "Epoch 59/100\n",
      "3474/3474 [==============================] - 2s 633us/step - loss: 1.6136e-04 - val_loss: 0.0015\n",
      "Epoch 60/100\n",
      "3474/3474 [==============================] - 2s 630us/step - loss: 7.0319e-04 - val_loss: 2.9061e-04\n",
      "Epoch 61/100\n",
      "3474/3474 [==============================] - 2s 633us/step - loss: 0.0031 - val_loss: 0.0387\n",
      "Epoch 62/100\n",
      "3474/3474 [==============================] - 2s 639us/step - loss: 0.0077 - val_loss: 2.9921e-04\n",
      "Epoch 63/100\n",
      "3474/3474 [==============================] - 2s 638us/step - loss: 6.5322e-04 - val_loss: 2.0436e-04\n",
      "Epoch 64/100\n",
      "3474/3474 [==============================] - 2s 631us/step - loss: 1.3656e-04 - val_loss: 5.9482e-04\n",
      "Epoch 65/100\n",
      "3474/3474 [==============================] - 2s 632us/step - loss: 2.9299e-04 - val_loss: 1.5963e-04\n",
      "Epoch 66/100\n",
      "3474/3474 [==============================] - 2s 633us/step - loss: 1.6212e-04 - val_loss: 4.2861e-04\n",
      "Epoch 67/100\n",
      "3474/3474 [==============================] - 2s 633us/step - loss: 1.5751e-04 - val_loss: 1.5390e-04\n",
      "Epoch 68/100\n",
      "3474/3474 [==============================] - 2s 632us/step - loss: 6.4034e-05 - val_loss: 1.5202e-04\n",
      "Epoch 69/100\n",
      "3474/3474 [==============================] - 2s 630us/step - loss: 0.0054 - val_loss: 0.0207\n",
      "Epoch 70/100\n",
      "3474/3474 [==============================] - 2s 629us/step - loss: 0.0044 - val_loss: 0.0017\n",
      "Epoch 71/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 7.3745e-04 - val_loss: 1.5187e-04\n",
      "Epoch 72/100\n",
      "3474/3474 [==============================] - 2s 638us/step - loss: 8.0038e-05 - val_loss: 1.3059e-04\n",
      "Epoch 73/100\n",
      "3474/3474 [==============================] - 2s 631us/step - loss: 1.0668e-04 - val_loss: 9.4630e-04\n",
      "Epoch 74/100\n",
      "3474/3474 [==============================] - 2s 633us/step - loss: 2.4809e-04 - val_loss: 1.2788e-04\n",
      "Epoch 75/100\n",
      "3474/3474 [==============================] - 2s 632us/step - loss: 1.1370e-04 - val_loss: 1.4176e-04\n",
      "Epoch 76/100\n",
      "3474/3474 [==============================] - 2s 631us/step - loss: 8.3112e-05 - val_loss: 1.1200e-04\n",
      "Epoch 77/100\n",
      "3474/3474 [==============================] - 2s 629us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 78/100\n",
      "3474/3474 [==============================] - 2s 633us/step - loss: 8.9422e-04 - val_loss: 0.0012\n",
      "Epoch 79/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 0.0030 - val_loss: 8.7322e-04\n",
      "Epoch 80/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 7.3366e-04 - val_loss: 0.0013\n",
      "Epoch 81/100\n",
      "3474/3474 [==============================] - 2s 629us/step - loss: 3.1247e-04 - val_loss: 7.8781e-04\n",
      "Epoch 82/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 8.0008e-04 - val_loss: 4.8120e-04\n",
      "Epoch 83/100\n",
      "3474/3474 [==============================] - 2s 630us/step - loss: 0.0018 - val_loss: 0.0051\n",
      "Epoch 84/100\n",
      "3474/3474 [==============================] - 2s 627us/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 85/100\n",
      "3474/3474 [==============================] - 2s 630us/step - loss: 0.0013 - val_loss: 2.2238e-04\n",
      "Epoch 86/100\n",
      "3474/3474 [==============================] - 2s 629us/step - loss: 6.3636e-04 - val_loss: 0.0016\n",
      "Epoch 87/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 6.4462e-04 - val_loss: 1.8977e-04\n",
      "Epoch 88/100\n",
      "3474/3474 [==============================] - 2s 629us/step - loss: 1.8084e-04 - val_loss: 3.8830e-04\n",
      "Epoch 89/100\n",
      "3474/3474 [==============================] - 2s 630us/step - loss: 4.5439e-04 - val_loss: 0.0041\n",
      "Epoch 90/100\n",
      "3474/3474 [==============================] - 2s 629us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 91/100\n",
      "3474/3474 [==============================] - 2s 634us/step - loss: 6.7401e-04 - val_loss: 4.6857e-04\n",
      "Epoch 92/100\n",
      "3474/3474 [==============================] - 2s 628us/step - loss: 1.0597e-04 - val_loss: 1.3552e-04\n",
      "Epoch 93/100\n",
      "3474/3474 [==============================] - 2s 629us/step - loss: 1.5622e-04 - val_loss: 5.7278e-04\n",
      "Epoch 94/100\n",
      "3474/3474 [==============================] - 2s 629us/step - loss: 4.3072e-04 - val_loss: 7.4934e-04\n",
      "Epoch 95/100\n",
      "3474/3474 [==============================] - 2s 629us/step - loss: 0.0020 - val_loss: 0.0046\n",
      "Epoch 96/100\n",
      "3474/3474 [==============================] - 2s 633us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 97/100\n",
      "3474/3474 [==============================] - 2s 629us/step - loss: 8.4826e-04 - val_loss: 3.2159e-04\n",
      "Epoch 98/100\n",
      "3474/3474 [==============================] - 2s 629us/step - loss: 3.4162e-04 - val_loss: 6.6230e-04\n",
      "Epoch 99/100\n",
      "3474/3474 [==============================] - 2s 629us/step - loss: 0.0043 - val_loss: 0.0013\n",
      "Epoch 100/100\n",
      "3474/3474 [==============================] - 2s 630us/step - loss: 0.0068 - val_loss: 8.4204e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaled2=scaled[:-10]\n",
    "y=np.ediff1d(scaled2[:,3])\n",
    "y1 = np.empty([len(y)], dtype=np.float32)\n",
    "for i in range(len(y)):\n",
    "    if y[i] >= 0:\n",
    "        y1[i] = 1.0\n",
    "    else:\n",
    "        y1[i] = 0.0\n",
    "Inp = Input(shape=(1, 9))\n",
    "inp = Inp\n",
    "inp = inp=Dense(10000, activation='selu')(inp)\n",
    "inp = inp=Dense(2000, activation='selu')(inp)\n",
    "inp = inp=Dense(1000, activation='selu')(inp)\n",
    "inp = inp=Dense(500, activation='selu')(inp)\n",
    "inp = inp=Dense(200, activation='selu')(inp)\n",
    "inp = inp=Dense(100, activation='selu')(inp)\n",
    "#inp = Dropout(0.05)(inp)\n",
    "inp = inp=Dense(50, activation='selu')(inp)\n",
    "#inp = Dropout(0.15)(inp)\n",
    "inp = inp=Dense(20, activation='selu')(inp)\n",
    "inp = inp=Dense(10, activation='selu')(inp)\n",
    "inp = inp=Dense(1)(inp)\n",
    "model = Model(Inp,inp)\n",
    "ad = optimizers.Adam(lr=0.0005)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=5, min_lr=1e-8)\n",
    "model.compile(loss='mse', optimizer=ad)\n",
    "history = model.fit(train_X.reshape(-1,1,9), train_y.reshape(-1,1,1), epochs=100, batch_size=128, validation_split=0.1, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(history.history['loss'], label='multi_train')\n",
    "pyplot.plot(history.history['val_loss'], label='multi_test')\n",
    "pyplot.legend()\n",
    "pyplot.yscale('log')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regession accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected input_2 to have shape (15, 56) but got array with shape (1, 56)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ecfc0946c1d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m56\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdiff1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mediff1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mediff1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmul\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdiff1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1815\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[0;32m   1816\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1817\u001b[1;33m                                     check_batch_axis=False)\n\u001b[0m\u001b[0;32m   1818\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1819\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    121\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking : expected input_2 to have shape (15, 56) but got array with shape (1, 56)"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(scaled[-21:-1,:].reshape(20,1,56))\n",
    "test_y = scaled[-20:,3].reshape(10,1,1)\n",
    "diff1=np.concatenate((np.ediff1d(test_y[:,0]).reshape(len(test_y[:])-1,1),np.ediff1d(yhat[:,0]).reshape(len(yhat[:])-1,1)),axis=1)\n",
    "mul = np.multiply(diff1[:,0],diff1[:,1])\n",
    "print(len(mul[mul>=0])/len(mul))\n",
    "\n",
    "\n",
    "pred = model.predict(scaled[-2,:].reshape(1,1,56))[0][-1] - scaled[-2,3]\n",
    "y_test = scaled[-1,3]-scaled[-2,3]\n",
    "for i in range(1,100):\n",
    "    pred = np.append(pred, np.array([model.predict(scaled[-2-i,:].reshape(1,1,56))[0][-1]])-scaled[-2-i,3])\n",
    "    y_test = np.append(y_test, scaled[-1-i,3]-scaled[-2-i,3])\n",
    "mul = np.multiply(pred, y_test)\n",
    "len(mul[mul>=0])/len(mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97030538]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.delete(scaled,3,1)[-2,:].reshape(1,1,55))[0][-1])\n",
    "print(scaled[-1,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classification accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 56 into shape (1,15,56)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-0df3d7ff2ab8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m56\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mscaled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m56\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mscaled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 56 into shape (1,15,56)"
     ]
    }
   ],
   "source": [
    "pred = model.predict(scaled[-2,:].reshape(1,15,56))[0][-1]\n",
    "y_test = scaled[-1,3]-scaled[-2,3]\n",
    "for i in range(1,10):\n",
    "    pred = np.append(pred, np.array([model.predict(scaled[-2-i,:].reshape(1,15,56))[0][-1]]))\n",
    "    y_test = np.append(y_test, scaled[-1-i,3]-scaled[-2-i,3])\n",
    "p=np.empty([len(pred)])                   \n",
    "for i in range(len(pred)):\n",
    "    if pred[i] >= 0:\n",
    "        p[i] = +1.0\n",
    "    else:\n",
    "        p[i] = -1.0\n",
    "mul = np.multiply(p, y_test)\n",
    "len(mul[mul>=0])/len(mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4666666666666667"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(scaled2[-11:-1,:-1].reshape(1,10,14))[0][-1]\n",
    "y_test = scaled2[-1,3]-scaled2[-2,3]\n",
    "for i in range(1,15):\n",
    "    pred = np.append(pred, np.array([model.predict(scaled2[-11-i:-1-i,:-1].reshape(1,10,14))[0][-1]]))\n",
    "    y_test = np.append(y_test, scaled2[-1-i,3]-scaled2[-2-i,3])\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(y_test.reshape(-1, 1))\n",
    "#y_test = scaler.transform(y_test.reshape(-1, 1))\n",
    "#y_test=y_test[:,-1]\n",
    "#pred = scaler.transform(pred.reshape(-1,1))\n",
    "#pred = pred[:,-1]\n",
    "p=np.empty([len(pred)])                   \n",
    "for i in range(len(pred)):\n",
    "    if pred[i] >= 0.0:\n",
    "        p[i] = +1.0\n",
    "    else:\n",
    "        p[i] = -1.0\n",
    "mul = np.multiply(p, y_test)\n",
    "len(mul[mul>=0])/len(mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "20/20 [==============================] - 0s 900us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.97523295879364014, 0.34999999403953552]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44908598,  0.55091399],\n",
       "       [ 0.31791157,  0.68208849],\n",
       "       [ 0.9359858 ,  0.0640142 ],\n",
       "       [ 0.50761443,  0.49238551],\n",
       "       [ 0.93432957,  0.06567046],\n",
       "       [ 0.20137239,  0.79862761],\n",
       "       [ 0.80506045,  0.19493958],\n",
       "       [ 0.30424833,  0.69575167],\n",
       "       [ 0.34166884,  0.65833116],\n",
       "       [ 0.42683479,  0.57316518],\n",
       "       [ 0.2518304 ,  0.7481696 ],\n",
       "       [ 0.61474901,  0.38525099],\n",
       "       [ 0.37301657,  0.6269834 ],\n",
       "       [ 0.16675115,  0.83324885],\n",
       "       [ 0.46943262,  0.53056735],\n",
       "       [ 0.3657099 ,  0.6342901 ],\n",
       "       [ 0.49318859,  0.50681144],\n",
       "       [ 0.64690256,  0.35309747],\n",
       "       [ 0.37790051,  0.62209946],\n",
       "       [ 0.65741855,  0.34258151]], dtype=float32)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.predict(test_X)\n",
    "\n",
    "plt.plot(pred)\n",
    "plt.plot(test_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897],\n",
       "       [ 0.4816103,  0.5183897]], dtype=float32)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_X)\n",
    "#pred = scaler.inverse_transform(pred.reshape(-1,1))\n",
    "#pred = pred[:,-1]\n",
    "p=np.empty([len(pred)])\n",
    "y_test=np.empty([len(pred)])\n",
    "for i in range(len(pred)):\n",
    "    if pred[i,-1] >= 0.5:\n",
    "        p[i] = +1.0\n",
    "    else:\n",
    "        p[i] = -1.0\n",
    "    if test_y[i]>= 0.5:\n",
    "        y_test[i] = 1.0\n",
    "    else:\n",
    "        y_test[i] = -1.0\n",
    "mul = np.multiply(p, y_test)\n",
    "len(mul[mul>=0])/len(mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_X)\n",
    "p=[]\n",
    "for i in range(len(test_X)):\n",
    "    p.append(pred[i]-test_X[i,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42857142857142855"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_X)\n",
    "diff1=np.concatenate((np.ediff1d(test_y).reshape(len(test_y)-1,1),np.ediff1d(pred[:,0]).reshape(len(pred[:])-1,1)),axis=1)\n",
    "mul = np.multiply(diff1[:,0],diff1[:,1])\n",
    "len(mul[mul>=0])/len(mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 14, 8), (10, 2))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X2 = scaled[-15:-1,:].reshape(1,14,8)\n",
    "test_y3 = np.array(scaled[-1,-1]-scaled[-2,-1])\n",
    "for i in range(1, 10):\n",
    "    test_X2 = np.append(test_X2, scaled[-15-i:-1-i,:].reshape(1,14,8),axis=0)\n",
    "    test_y3 = np.append(test_y3, np.array(scaled[-1-i,-1]-scaled[-1-i+1,-1]))\n",
    "test_y2 = np.empty([len(test_y3),2])\n",
    "\n",
    "for i in range(len(test_y3)):\n",
    "    if test_y3[i] > 0:\n",
    "        test_y2[i] = [1,0]\n",
    "    else:\n",
    "        test_y2[i] = [0,1]\n",
    "test_X2.shape, test_y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96497095"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(scaled2[-16:-1,:].reshape(1,15,56))[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(pred[-15:].reshape(15,1), label='predict')\n",
    "pyplot.plot(y_test[-15:])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.plot(model.predict(scaled[-11:-1,:].reshape(10,1,56)).reshape(10))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 22 into shape (1,2,4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-b092d6409452>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 22 into shape (1,2,4)"
     ]
    }
   ],
   "source": [
    "pyplot.plot(np.append(scaled[-10:,-1],model.predict(scaled[-14:].reshape(1,14,4))))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((test_X[:, :-2],yhat), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,-2:]\n",
    "# invert scaling for actual\n",
    "#test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_X[:, :-2], test_y), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
